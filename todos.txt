[GENERAL]
1. Check if this works with Deno; 	

[v0.3]
2. Version Plan: Signatures. 

	The entire release is totally breaking. 
	Dedicated to fixing signatures. 

		ULTIMATE ISSUE TO SOLVE: 

			Currently (as of finished v0.2), the library supports: 

				1. Table-parsers; 
				2. Streams; 
				3. Self-modifying parsers; 
				4. Four (if not more) kinds of predicates; 
				5. Two (if not more) kinds of handlers; 
				6. Generators; 
				7. Tokenizers; 
				8. Trees
				9. Various essential utils for functional parser-building and most common/typical parsing tasks
				10. Validators; 
				11. A Locator; 
		
		Now, the ONLY thing that it really does not have 
			(but that which can be of essence, whenever building complex/exotic/unconventional syntaxes')
			is STATE! 
		Thus, the library must become STATEFUL (that is, 
			FUNCTION SIGNATURES MUST CHANGE IN A WAY TO RECIEVE SINGLE OBJECTS, 
				ONE OF PROPERTIES OF WHICH IS THE STATE!)

		This, of course, means that whatever signatures were still "present" 
		within the last release would erode in this one (and VERY fast). 

		The 'state'	must allow to carry: 

			1. 'streams' array (current - 'input', a single 'Stream'); [ALLOWS MULTISTREAMING]
			2. 'state' object (contains properties to be shared/mutated)
			3. 'parser' object/function (in dynamic cases - the ParserMap itself, in static - only just the function)
			4. 'result' - a 'Pushable' (generalied): 

				4.1. This will have to be transformed into something that is both: A. General (as in v0.2); B. Powerful (like the builtin Array); 
					The final interface will have to both be an 'Array-equivalent' (in the sense that an 'Array' is viable), 
						and also be an interface (in that it can be implemented differently and be, for instance, of unlimited length).

				4.2. This is mutable; 
				4.3. This is a "list-like" result of the insofar obtained pieces of parsing

				In cases, when it's NOT an array (example: 'SourceGenerator'), one is to use an alternative with similar properties 
					(a 'Type'-equivalent, where 'Type' is the builtin type that it's supposed to "imitate", that is both potentially more powerful
						and equally capable of a given set of operations)
			5. 'finished' - a (modifiable) predicate, determining the point, at which the parsing function should halt (note: used by ALL the parsers): 
				There would be several predefined aliases for it, such as [SKETCHES (the actual things would be written in terms of the 5-object)]: 

					5.1. firstFinished = ({streams}) => streams[0].isEnd()
					5.2. allFinished = ({streams}) => streams.every((x) => x.isEnd())
			6. `changed` - the (ultimate) function used for construction of 'result' via `result = changed(result, out)`.

				TODO: for '.push' and '.concat' to work with it, change them to `push(x, y) := { x.push(...y); return x}` and `concat(x, y) := x.concat(y)` [remains the same...];
			
		This signature will permit creation of parsers for syntaxes previously impossible. 
		Of course, the behaviour of present parsers will, too, have to be changed/generalized, 
			and the v0.3 API is not naturally compatible with the previous ones (although, as it is only singature - it can still be fixed).

		The "default" behaviour of the parser function will still be defined by things such as 'StreamParser' or `SkipParser`. 

3. Idea for new functions: 

	NOTE: the 'utilities' and other parts of the library must ALL support the new 'stateful' signature...;

	3.1. a utility - 'find`: 2-layer of a `predcate/number` and a `Stream`; 

		It iterates the given stream (modifying it), and (from its current point), 
			finds all the elements of the stream that are in possession of the 
			desired property.
		It (then) proceeds to create an array of all the fitting stream elements.

		Predicate is also passed the 'i'; 

		If number is given, gets the 'n'th element of the `Stream`.
	3.2. a utility - 'revert' - reverts the stream, returns the copy

		Alters the stream, returns an array of all of its elements, 
			in reverse order.
	
	3.3. a utility - merge(mergeRule(...streams: Stream[]) => number, endRule: (...streams: Stream[]) => boolean, iterationRule: (...streams): Stream[])(...streams: Stream[]) - for merging separate streams 

		Iterates the '...streams' using 'iterationRule', until the moment that 
		`endRule` is false, and adds the 'streams[mergeRule(...streams)].curr()' to the final result (a general interface, of course...). 

	3.4. a utility - `extract`: 

		Reverse+generalization of 'limit' - splits a given Stream into 
			pieces, [extracted: any[][], remains: any[][]], 
			with: 
			
				Array(extracted.length).fill(0).map((_x, i) => [remains[i], extracted[i]]).flat().reduce((last, curr) => last.concat(curr), []) === transform((x) => x)(input)

		Where 'input' is the passed `Stream`.

		Useful for defining more complex predicate-based Pattern-s; 

	3.5. a utility-alias - `array` (same as `transform((x) => x)`)
	3.6. a utility `prolong` - concats the results of `transform((x) => x)`. 

		The result is an array consisting of elements of several different streams.

	3.7. StreamPattern: 

		A `Pattern` implementation based off `extract` and a `Stream`. 

	3.8. A general 'MultiIndex' interface, specific implementations. 

4. Better support for DynamicMaps: 

	Certain tokenizers/validators (and so forth), 
	do not have very good compatibility with DynamicMaps (namely - they are intended for usage with static ParserMap-s); 

	__Think__ of a way to make them "dynamic" as well (or, at the very least, create a Dynamic alternative); 

		[dilemma lies, primarily, in the choice between: 
			1. Ability to have faster code; 
			2. Haivng large chunks of (ultimately) repeating code, that could (otherwise) have been avoided had one had proper parsing/generation tools for JavaScript already; 
		]

		As the keys in question would have to be changed EVERY time, the implementation would (likely) have to change (as the target array would change correspondently...); 
		So, regardless, for these pieces (at least), the change ought to be slightly more significant.

5. PositionalValidator (validatorMap) - an idea for a `StreamLocator` alias. 
	A way to easily create `StreamLocator`s through `validationMap`s used for `Validator`s via: 

		streamLocator := (([found, pos]) => [!found, pos])(StreamLocator((input) => (!x || !x(input))(validityMap.index(input.curr()))))

6. PositionalStream: 

	Fix that. Currently, carries a (near) useless 'pos' property used by the 'StreamLocator'. 
	The 'pos' must be A RESULT OF A FUNCTION-CONVERSION! There ought to be another (optional, this time) property 'converter' 
		(defaulting to '(x) => x'), that is a part of 'Position' interface used by `PositionalInterface`. 

	THEN, one can create some fairly wild things through user-defined position-writing, 
		while ALLOWING to convert back from them 

			so that: 
				
				skip(position.convert())(input)

			skips to position 'position' in `inputs`.

7. NEGATIVE NUMBERS!

	Alter the 'predicateChoice' to allow for negative numbers (the '.prev'); 

8. Unite 'read' and 'limit': 

	Make a single interface or a union type and merge one function into the other. 

		IDEA: rename into 'consume' (as it describes functions of both of them). 

			Keep the default of `limit`; 
			Keep the signature of `limit`; 
			Keep both the 'Concattable' and 'Pushable' (or, unite them and use the library types instead of native ones [or do both...]); 

			Decide whether to do `.concat(input.curr()); input.next()` or `.push(input.next())` 
				[due to more complex interfaces possible that way, leaning towards the former]. 
			
			Think about '.concat' being non-modifying, while 'push' (intendedly) modifying.	
	The library (generally) should decide between COPYING and MODIFYING data structures. 

	From optimization standpoint, MODIFYING may be (and typically is, much) faster. 
		(As there would also be according '.copy' methods, this would probably be the further vector of development for it).
	
	The 'Strings' (Concattable-s) and 'Arrays' (Pushable-s) all, therefore, should have a single uniting Interface. 

	Call it 'Collector', with a 'prolong'/'collect' method. 

	Similarly, get rid of `Source`s, replace them with the same interface. 

	NOTE [again]: the v0.3 will be HIGHLY incompatible with the other versions due to major signature and interface changes (extensions, simplifications, generalizations). 	


	IDEA: use a general two-argument function `f(x, y)` for this 
		(thus, the user gains a FAR more general way of doing the whole things [+ with 'push' and 'concat', one can (pretty much) keep the current interfaces])

9. Get rid of `SourceGenerator`. 

	Develop a new (or improve/extend the old) language of the library. 
	Get rid of `SourceGenerator` (has become exceedingly useless - basically a simple composition of `parserChoice` and `read` without a predicate). 

	Replace with the more general types (the 'parsing' methods shall be used for "generation" as well...); 
	
10. Write proper JSDoc documentation for all this stuff...

	DO NOT add the 'docs' copies into JSDoc, INSTEAD, just reference them...

11. Fix the library's general interfaces: 

	Ultimately, the reason the problem is here at all is that... 
	
	TypeScript's being silly. 
		Again. 
	
	It doesn't seem recognize a `string`, for instance, as an `Indexed`, because this would require for them to be OBJECTS. 

		But the `string` is a primitive. 
		So one has to target it SPECIFICALLY... 

			Regardless, while the interfaces do serve their (ultimate) purpose, they do miss this. 
			Problem arises due to "special" treatment of JS 'primitive' types (which are, nonetheless, equally viable as objects...)

12. Certain general interfaces that are supposed to be 'friendly' togethter aren't too much so (example: buggy 'Source' and 'Concattable'). 

	That, too, is to be fixed...

13. TypeScript is realllyyyyyyyy dumb...

	The (x: X) => any is NOT convertible to (x?: X) => any. 

	Which is fucking ridiculous. 
	Due to the fact that, in essence, it means that `x` CAN be undefined, 
		instead of meaning that the element `x` can be ABSENT from the signature. 
	
	The absence is, thus, to be represented via unions of different function signatures: `|`. 

	13.1. SIMILARLY: for interfaces like `Stream` with optional properties...

		INSTEAD of marking a property optional, 

		Create extensions that would ENFORCE those properties: 
			for instance: 

				1. RewindableStream (.rewind); 
				2. CopiableStream (.copy); 
				3. ReversibleStream (.prev); 
			
		Their intersections as types ('&') would grant desired interfaces. 

		CONSEQUENTLY: 

			Re-do the 'general' interfaces like this into UNIONS of 
				these sub-types and more general types (so that, "?." can be done...); 
			
			1. Stream -> 'BasicStream', then (and 'Stream' becomes a union of `BasicStream`, `RewindableStream`, and others...);

14. Mandatory ".isStart" method for the 'ReversibleStream' (.prev). 

	This method is the reverse of the '.isEnd'; 

15. A `PositionalStream` function. 

	It (ultimately) creates a basic `.pos` structure on a given stream for the price of one more `Stream` object and a callstack. 
	Every time an `input.next()` is called, it changes its own `pos` in accordance with the user's desire. 

16. 'regex.charRanges' signature: 

	Make it more varied (an array of):
		
		1. into a single 'string' array (where each pair of symbols is a range); 
		2. a single string/sequence of strings - a character.

17. The 'GeneralParser(change) => (initState: State) => any': 

	The most general parsing function. 
	Returns a parser accepting signature of 2., with 'result = change(result, out, state)', where result is the returned thing, 
		`result` is the final thing to be returned, 
		`state` is the state signature from 2., 
		`out` is the result of the parsing function [from 'state'].

18. Tree-construction task: 

	A comment from one of the projects, explaining it all: 

		// ! Problem: 
		// * Generally, trees consisting of different types of tokens [and, hence, structures], 
		// 		fall under THE SAME class of classification problems used for writing parsers and generators in 'parsers.js'. 
		// ^ SO, one OUGHT to create means for general out-of-the-box Tree-construction... using them; 
		
		// TODO: generalize the 'indexation' method of 'TableParser' (generally, create a method (table, next) => X := (x) => table.index(x)(x, next || X))

19. An IMMENSELY breaking change: 

	Rewrite the 'TableParser' as JUST `table`. 

	INSTEAD, relocate the 'current' alias logic into a separate definition utilizing the `extendKey` (namely, .extendKey(current)). 

	This would render v0.3 TOTALLY incompatible with the previous versions, as it would (then), use a COMPLETELY new set of abstractions, 
		(though based on, ultimately, the same ideas). 