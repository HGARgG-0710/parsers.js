[GENERAL]
1. Check if this works with Deno; 	

[v0.3]

NOTE: nope, the version is NOT finished. 

	-6. REFACTOR the INTERFACES; 

		Look for repetition; Examples: 

			1. IsEndCurrable & IsEndStartable; 

	-5. [reminder, until v0.3 is done] ADD 'Symbol.iterator' EVERYWHERE; 
		Some Stream-s implementations STILL lack it! 
		The ability to do: 

			for (const x of stream) {
				// ...
			}

		Over something relatively 'complex' (like a NestedStream), is absolutely AMAZING!

	-4. CHECK whether the current 'isCurrEnd' thing WORKS with empty streams; 
		[The 'isEnd' is initialized to 'false' BY DEFAULT! It'll have to walk AT LEAST one position];
			FIX THAT: the user should be able to give the 'initial' '.isEnd' checking-function; 

	-3. Write the JSDocs already (1.): 	

		Been laying it off for far-far-far too long now. 
		The library is literally impossible to apply for the new user. 

		JSDoc will help A LOT with accesibility. 

	-2. More typechecking-functions, 'is'-functions based off interfaces; 

		Many are missing appropriate functions for checking presence of properties...; 

	-1. CHECK EXPORTS FOR CORRECTNESS! 
		Primarily concerns missing exports in the 'Parser/' immidiate files; 

	1. THE BENCHMARK HATH SPOKEN! 

		Based off a (very) approximate heuristic of 'consume' (which was) 'the fastest/simplest' of them all...; 
		The simple 'iteration' approach IS (quite a bit) faster; 
	
		1. 3.3-3.5
		2. 3.19, 3.20
		3. 3.7, 3.8
		4. 3.23. 
		
		Utilities to keep: 
			
			1. skip - this doesn't output ANY kinds of data structures; 
			2. array - basic thing (Stream-to-array conversion); 
			3. has - no data-structure output; 
			4. nested - far too specific (a task that is not always accomplishable equally efficiently via 'Stream'-s: This keeps a counter, whilst the NestedStream doesn't); 

A. testing [1. Create list of modules to be tested]; 
B. documentation (change/fix it...); 
C. rewrite the CHANGELOG [too much has been altered since the "initial" v0.3]; 

[v0.4]

1. STACK! 
	The library is not too stack heavy, BUT it does have an (ultimate) stack-limitation
		when working with NestableStream-s and the 'nested' util (generally, anything that is NON-FLAT);
	This is very much impossible to solve on its own; 

	SOLUTION: use the CPS style. 
		Re-implement library (whilst keeping the non-CPS version) in CPS, 
		with an infinite 'stack'; 

	! THIS WILL REQUIRE FOR ONE TO FIRST IMPLEMENT THE INFINITE CPS-BASED STACK LIBRARY!
	That one should: 
		0. Be written in TypeScript; 
		Include Types: 
		1. InfiniteStack; 
		2. CPSArray (this is, ultimately, a CPS version of JS array);

	As, CPS is (quite) time-costly to actually run (due to the stack unwinding [primary] + amount of stack usage + additional checks...),
		this sort of thing would be useful for applications where speed of little importance
			(that is: NOT things like apps/websites/interpreters, and so forth; Stuff like AOT-compilers, perhaps);
	
2. Write proper JSDoc documentation for all this stuff...
	DO NOT add the 'docs' copies into JSDoc, INSTEAD, just reference them...

3. Add various optimization data structures + utils + parser properties: 

	3.1. bufferize(process, size)(tree) - util

		Given a 'Tree', returns an array of values: 

			{
				index: number, 
				childNumber: number,
				value: any
			}

		This (ultimately) does THE SAME thing
			as the 'TreeStream', BUT without losing the children's Tree-information. 
		Unlike the 'TreeStream', this is intended as
			a more persistent data structure with faster, 
			and NON-LINEAR (important) access than TreeStream.
		
		Would return a 'NodeBuffer' (which is just a kind of an array); 
		Indexing an array could be (potentially) noticeably faster than walking through a Tree 
			(particularly so with the 'TreeStream'); 

		The 'index' is the index FROM THE BEGINNING of the buffer to the current Node. 
		The 'childNumber' is the number of children that come AFTER the current node. 
			Children are read between positions from 'index' to 'index + childNumber', 
				with each 'child' being checked for its own children
					(which, if nonzero, are excluded from the current children, and are instead counted as grandchildren). 
		
		The 'value' is the actual value at the index (note: being 'process'ed - this is intended for removing/keeping children, primarily); 

		If size is used, it will ONLY use this many items from the tree (up to the maximum amount - the rest of positions will be assigned to 'undefined'); 

	3.2. Add a 'state.size' property to the parsers. 
		This (ultimately) counts the number of items inside the tree.
		Can be used with 'bufferize': 

			bufferize((x) => x, pstate.size)(pstate.result)

	3.3. ProlongedStream; 
		The Stream-equivalent of 'prolong' utility; 
		'Concatenates' different streams into one; 

	3.4. SubStream: 
		The Stream-equivalent of the 'find' utility (finds ALL occurences of the given 'position') - this [effectively], 
			gives a new Stream that has only the items with given 'position' (either property-function or a single element at that position, if any); 

		The property function has an 'i: Position' argument for THE POSITION!
	
	3.5. DelimitedStream: 
		The Stream-equivalent of 'delimited'; 
		Does THE SAME stuff as the 'delimited' function, but on Streams: 
			Skips the elements deemed 'delimiters', 
				'handle's the elements deemed 'non-delimiters'; 

	Note: the new object-oriented approach will enable better speed and lesser structure-copying (better memory use); 
		PLUS: one can have the 'Streams' in question working AS TREES without the necessity for creation of the actual TreeStream-s
			(as the recursive Stream-s more or less serve the same function - only problem is populating them with the appropriate kinds of objects); 

	3.6. TreeStream: create two versions; 

		The 'TreeStream' (currently) is the 'LL' pre-order tree traversal algorithm Stream-implementation; 
		There should be ANOTHER - the 'LR' post-order tree traversal; 

		Rename the 'TreeStream' to 'TreeStreamPre', and create an implemnetation for the 'TreeStreamPost'; 
		This is (particularly) useful for some types of interpreters; 

		The Pre  visits the node, then its children one-by-one starting from the beginning. 
		The Post visits first the children, only THEN the parent.

	3.7. recursiveTransform - a utility; 
		This recursively transforms all the sub-Stream-s within the given Stream; 
		It, effectively, frees the user from the necessity of writing the recursive functionality into their transformation themselves; 

	3.8. NestedlyTransformed - an object-oriented version of the 'recursiveTransform'; 

	3.9. Implement a 'PartialValidator': 
		This, ultimatly, works in THE SAME WAY as the 'PatternValidator' and 'PatternTokenizer' (GENERALIZE THEM TO A SINGLE FUNCTION ALREADY!)
		Gets the recursive structure with all the 'split' and 'inserted' bits; 
		The 'PartialValidator' would RETURN THE INFORMATION FOR INFERENCE OF CORRECT/INCORRECT PARTS! 
		[Which it does by 'numbering' particular portions of a given Pattern]; 
		This would allow for a greater ability to analyze/point-out the errors in the original input;

		Unlike plain PatternValidator, it would return ALL the possibly available error information, not just the stuff about the index of the "failed" check, or coverage; 

	3.10. Implement a 'level-by-level TreeStream': 

		It would get an initial given 'level' (tree root), walk through all of its '.children', 
			then walk each of the '.children' themselves as levels (one after another...), THEN descending lower...; 

	3.11. Add a 'HashClass'-implementation of 'MapClass'; 

		Basically, takes the 'hash' function (rough sketch) and returns a hash-table based off it...: 

			function HashTable (hash) {
				return function (values, keys = new Set(), default = null) {
					return function (x) {
						return !keys.size || keys.has(x) ? values[hash(x)] : default
					}
				}
			}

		Great for generalizing optimizations of tables/hashes/maps...

		Implement special  cases of this ALSO (PARTICULAR hash-functions...): 

			1. LengthHash: 

				This is excellent for string-identifiers; 
				Given a set of strings (THAT CAN BE UPDATED!),
					one has a hash function: 

						(string) => string.length

				The thing in question is (supposed) to map a given string to an array/collection 
					of other strings of equal length, then map in this collection (which has a different interface...);

				NOTE: ANYTHING with a '.length' property is usable with this;
				
			2. TreeHash (a kind of 'Hash', based off 'Tree'-s): 
				Basically, given an 'Indexed<Type>' (WITH A '.length'), and given an 'array-tree', one does (rough sketch, indexation): 

					function ArrayTreeHash (tree) {
						return function (x) {
							let current = tree
							for (let i = 0; i < x.length; ++i) current = current[x[i]]
							return current
						}
					}

				NOTE: the actual 'TreeHash' would be more general and use 'x' as a MULTIINDEX!
					(tree) => tree.index(x)
					BUT: for this, it'd require a more 'generalized' version (in particular, USE LOOPS INSTEAD OF '.reduce')

				This can be used with strings/

	3.12. __ALWAYS__ USE 'for'-loops INSTEAD OF '.reduce'!
		This makes code MUCH more general. 
		In particular, one does so with the 'Tree'-s; 
		It'd allow to (for instance) store identifiers, and getting them via 'loops'; 

		Excluding some few special cases (like 'childIndex'), walk through the project, 
			AND REPLACE un-place-ly '.reduce'-s with proper loops...

	3.13. Add a module SPECIFICALLY for working with strings/identifiers/Sequence-s (currently: the 'Indexed' interface); 

		In particular, functions/abstractions: 

			1. UniqueSequenceTree;

				This is an 'IndexMap'+'Tree'-implementation working like: 

					1. '.index' of a given 'string' (or another '.length'-having structure) BASICALLY, finds the first "unique" level it's on; 

						So, for instance, having a set: 

							{ ann, ant, ben }

						Would yield an IdentifierTree: 

							0   1 2
							a,b-n-n,t

						This (basically) uses recursive objects + indexation
						(
							ant is found in 3 iterations; 
							an is found in 2 iterations; 
							'ben' is found in 1 iteration (only 'b' is stored);
						)

				Note: this implements a HashMap's 'hash'; 
				This is VERY good for frequent accesses to THE SAME value; 

			2. BinarySearchTree; 

				Same as 'UniqueSequenceTree', BUT it implements a Binary Search Tree.
				It works based on a provided comparison (a very rough indexation sketch): 

					function BinarySearchTree(tree, comparison) {
						return function (x) {
							let current = tree
							let greater
							while (current.length) current = current[+comparison(current, x)]
							return current.value
						}
					}
				
				NOTE: with (x, y) => x > y, can be used with identifiers; 

			3. shorten(names); 
				Given a sequence of "names" (strings/sequences),
					and a 'comparison' predicate for each of its elements,
						it would implement a name-shortening algorithm, 
							that would preserve the name uniqueness;
				
				The return value is an IndexMap; 

			4. renameable(names);
				Given an IndexMap of names (which could come from, for instance, 'shorten'), 
					the method: 

					1. Re-orders;
					2. Creates new name-map entries;

				In a fashion that would allow straightforward implementation of a sequential "exact replacement algorithm" based on the output: 

					1. Loop through a list of name-maps; 
						2. [In the loop] Rename current encounters of a name with its mapped value;	
					
				There are 2 operations that may be necessary: 

					1. creation of temp-names (when collisions in present names are far too high to re-order);
					2. re-order; 
				
				The algorithm for the 'renameable' function: 

					0. Keep the cached (met) names in a 'Set'; 
					1. Loop through the 'names' given: 
						1.0. If the name is in the cached Set, continue; 
						1.1. If the current 'value' of the 'name' is already present amongst 'keys' (another loop): 
							1.1.1. put the keys in question BEFORE the current value;
							1.1.2. '.swap' the two indexes;
							1.1.3. go one position back (because now one needs to check the "others" now); 
							1.1.4. cache the current amongst the checked names in a 'Set', (so that one doesn't get into an infinite loop);

	3.14. Replace the 'Tree' methods with in-place algorithms (not what this currently is...); 
		The 'copying' for Tree-s should be a WHOLE SEPARATE thing with ITS OWN module; 
		NOTE: the 'copying' in question occurs in methods 'MultValueTree' and 'RecursiveArrayTree'; 

		Namely: 

			1. RecursiveCopy:

				This is a method that deals with the 'ConstructibleTree's interface (basically, trees that can also be [generally] modified...);
				It creates a new such tree based off the current one; 

				Uses a general interface to copy arbitrary trees; 
				There has to be a 'flatCopy(): Tree' function for a given tree
					(which, repeated recursively, would yield a new tree, 
						and allow to preserve the reference to the underlying children WITHOUT
							preserving the reference to the tree itself...);

				This would be a 'FlatCopiableTree'; 
	
	3.15. Create a 'ModifiableStream' interface;

		It is (basically) a Stream, into which things can be INSERTED, whilst it is iterated. 
		Id est: 

			// ...
			input.next()
			input.insert(X) // calls another 'input.next()'; input.curr() now is 'X'; The thing RETURNS the result of the 'input.next()';

		Implement various different kinds of ModifiableStream-s; 

		1. A 'ModifiableTreeStream' "interface" (set of TreeStream-related implementations) would be a 'ConstructibleTree';

			There'd be different ModifiableTreeStream-s; 
			Their '.insert' would be based off how the tree was visited: 

				1. pre-order: it adds a NEW FIRST child to the current tree's node;
				2. post-order:
					1. IF current node has a parent already, adds a new parent to it
						(the current node; ID EST, adds a new CHILD to the current parent, and makes it the parent of the current node...)
					2. Otherwise, adds a node that is a FIRST CHILD of the current one; 
			
			There would also be some 'special' methods on 'TreeModifier', INDEPENDENT of the 'ModifiableTreeStream'-s [which would work with the TreeContext-s themselves]: 
			
				1. "insertSibling", which would insert a next sibling of the current element; 
				2. "insertLast", which would insert a child TO THE END of the tree's '.children';
				3. "insertChild", which would insert a child at a given index; 
				4. 'prependSibling', which would add a sibling BEFORE the current child; 

				PROBLEM: this sort of thing would OCCASIONALLY INVALIDATE the 'last' index; 
					It would have to be re-computed in such cases; 

			NOTE: there'd be a special new "class" of objects called 'TreeModifier' (analogous to 'TreeWalker'); 
				NOTE: Due to how the 'multi-index' of a 'Tree' would be "contained" within the 'TreeWalker',
					yet it would STILL need to be accessed by the 'TreeModifier' [in Stream Contexts...], 
						one might NEED to unite the two...; 

					IDEA: TreeIndexContext;
						This, basically, contains a triple: 

							{
								index: MultiIndex
								walker: TreeWalker
								modifier: TreeModifier
							}

						And the TreeWalker, TreeModifier, would be 'bound' to the current one (that is, they'd be taking an argument of 'multindex');

			The 'TreeModifier' implementations would HAVE to have a sort of "Modifiable" Tree (which is a special case of a 'Tree'); 
			A 'ChildrenTree' (Tree with '.children') is a GREAT fit for it...; 

		2. A 'ModifiablePositionalStream' would be a wrapper around another 'PositionalStream', 
			which would have a map of 'Positions', into which things were 'inserted', and would return new stuff accordingly...
			It is ALSO a 'PositionalStream'; 

			NOTE: for this stuff to WORK generally, one needs to define an 'AdditivePosition',
				one for which the 'skip(stream: PositionalStream, plus: Position)', or 'add(stream: PositionalStream, plus: Position)', 
					would exist. 

					'Number' special case of 'add(...)': 
						(a, b) => a + b
					
					Basically, just "goes forward"; 
					Similarly, there'd be a 'backout(stream: PositionalStream, plus: Position)' [or call it 'return'] method for these; 

					For numbers, definition is: 
						(a, b) => a - b

			The ModifiablePositionalStream would be a PositionalStream ALSO, which would permit one to 
				"stack them up" on top of one another (which is good for semantics separation...). 

		3. A 'ModifiableSplicableStream' would be a 'ModifiableStream' for 'Splicable'-s: 

			A 'Splicable' is an interface (extension of 'Indexed') with an Array-like .splice(index: number, toDelete: number, ...items: any) interface;
			Arrays are splice-ables; 

			The implementation would (basically) do: 

				{
					...InputStream(splicable),
					insert: function (X) {
						this.input.splice(this.pos, 0, X)
					}
				}
	
	3.16. MORE WORK on the 'IndexMap'; 
		
		Things to do: 
			1. add a '.swap' method (for swapping two positions); 

	3.17. CREATE A LOT OF Proxy-based OPTIMIZATION STRUCTURES!
		These are MIGHTY! [allow to save memory, and so forth...]; 
		IDEA: maybe, even create a library for these...; 
		
	3.18. Expand on the 'Position' type further;

		Allow for creation of more "exotic" types;
		Example: 

			"go up to nearest point in the past defined by predicate 'P', then another 5 positions", 

		should be something like: 

			[P, 5] // with 'P.direction = false'; 
		
		Allow "nesting" positions like so, create a proper PositionEvaluator (current thing is VERY limited); 

		The 'RelativePositionEvaluatorStream' would (ultimately) create a 'Stream' of values, defined by this "sequence"
			of Position-s (call it 'PositionSequence = Position[]'), and which would be entirely relative to one another; 

		The 'AbsolutePositionEvaluatorStream' would (similarly) interpret a sequence of 'Position's,
			but relative to the initial Stream (not one another).
		
		Then, GENERALIZE THIS to a 'PortionPosition' [which is the pair '[Position, Position]' used in 'LimitedStream'],
			to also use this with 'LimitedStream';

		So, 'PositionSequence = (Position | [Position, Position])[]' will define a new Stream based of a given one
			via the 'AbsolutePositionEvaluatorStream' and 'RelativePositionEvaluatorStream'; 

	3.19. MergeStream - equivalent of the 'merge' util; 
		As per 3.24 - replace functional API with OOP; 

	3.20. SplitStream - generalization of 'extract' util (as per 3.24.), reverse of 'MergeStream';

		Based off a given set of predicates (by default, if set size is 1: {P}, uses 2: {P, !P}),
			it defines a set of non-interlocking streams; 
		The predicates are interpreted to be 'greedy', in the sense that each will work to increase its Stream's size
			FOR AS LONG AS IT CAN.
	
	3.21. RELAX overly demanding interface and types definitions/requirements;
		Example: inputStreamCopy, inputStreamNavigate; 

			These do not NEED to have all the parts of the 'InputStream' definition (even though they are originally implemented to work with it);
			RE-DEFINE them...;

	3.22. [Idea?] Create an error-handling API for the 'v0.4';
		Create means of: 

			1. Stacking different levels of exceptions (the 'try-catch' blocks); 
			2. Assigning relevant debug information to them;

		This is (primarily) for the development process of the parsers; 
		
		Define a Catcher [rough sketch]: 

			function Catcher (info: DebugInfo, logger: Function) {
				return function (thing: Function, thisArg: any, args: any) {
					try {
						thing.call(thisArg, ...args)
					} catch (e) {
						logger(info)
						throw e // NOTE: THIS here is to represent DEPTH [as parsers can be VERY recursive indeed, it may be needed to eliminate the recursive errors on a case-by-case basis]; 
					}
				}
			}

		Although... This is rather general. Perhaps, better implement as a separate package; 

	3.23. Re-define the 'Parser' (StatefulStream): 

		Currently, a 'Parser' is a result of 'GeneralParser'; 
		This is NOT what one wants; 

		In particular, one needs a thing called STATEFUL STREAMS (StatefulStream); 

		Basically, this is a 'BasicStream' with the '.state' property; 
		This is very useful for complex parsing operations that DO NOT REQUIRE full-input parsing (one can delay execution); 

		ADD a 'Stateful' function, which does [basically]: 

			function Stateful (state: object) {
				return function (x: any) {
					x.state = state
				}
			}

		[Note: this can ALREADY be used in the form of 'Stateful' with 'StreamTokenizer' and 'TransformedStream']; 

		
	3.24. limitedStreamNavigate: FLAWED!
	
		Should handle the case where the '.pos' is A FUNCTION [but the 'position' ISN'T]; 
		THIS [fundamentally] needs the separation between the 'relative' and 'absolute' '.navigate'; 

			Once these are implemented, there'll be no problem whatsoever... 

			The (primary) issue with '.navigate'-ing using predicates is that it's NOT possible to navigate (generally) ABSOLUTELY using them; 
			Only the relative navigation is possible; 

			SEPARATING the navigation into 'absoluteNavigate' and 'relativeNavigate' (and defining the actual '.navigate' as the CONJUNCTION of the two), 
				will largely solve the issue. 
			
	3.25. MemoizableStreamClass: 

		This is a generalization of StreamClass; 
		The StreamClassInstance-s are ONLY capable of memoizing the very first value obtained via 'initCurr'; 

		This would (additionally) have two more methods: 

			1. memoize() - memoizes the value (any further .next() changes the value of the Stream, but '.curr' remains THE SAME); 
			2. unmemoize() - returns back to the flow of the Stream; 

	3.26. Minor refactoring: 

		Create a special case for the 'StreamClass' - the 'WrapperStreamClass'; 
			Basically, this works in a fashion similar to the 'InputStream', 'TransformedStream', and 'NestedStream', and others such (generally, UnderStream-s and Inputted): 

				1. There is 'iter' function (for iteration); 
				2. There is 'curr' function (for 'initGetter' and the definition of 'baseNextIter'); 
				3. Then, the 'baseNextIter' is defined as: 

					{
						iter.call(this)
						return curr()
					}
	
4. Dependency management: 

	4.1. Create a 'proxy-op' library SPECIFICALLY for various optimizations based on Proxy-functions on different types/kinds of objects;	
		4.1.1. These (sometimes) can help GREATELY reduce memory-consumption; Example: the Slicer; Include those there...; 
