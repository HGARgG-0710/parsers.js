[GENERAL]
1. Check if this works with Deno; 	

[v0.3]

NOTE: nope, the version is NOT finished. 

	Things to do before re-starting the testing all over again: 

		0. DO the dependency-management bit (about 'pointer' + 'summat.ts'); 
			0.1. The 'structCheck' IS BAAD!
		
		AFTER EVERYTHING ELSE: 

		1. DURING TESTING [possible RE-DO AGAIN!]: 

			Make a micro-benchmark, for comparing execution time of functional and OO API;
			IF OO is faster, IMPLEMENT it in the '3.0' version (NOT v0.4) + REPLACE the functional API with it...;

			IF it proves faster, do: 

				1. 3.24, 2.25
				2. 3.4-3.8
				3. 3.10, 3.11


A. testing [1. Create list of modules to be tested]; 
B. documentation (change/fix it...); 

For v0.4: 

1. STACK! 
	The library is not too stack heavy, BUT it does have an (ultimate) stack-limitation
		when working with NestableStream-s and the 'nested' util (generally, anything that is NON-FLAT);
	This is very much impossible to solve on its own; 

	SOLUTION: use the CPS style. 
		Re-implement library (whilst keeping the non-CPS version) in CPS, 
		with an infinite 'stack'; 

	! THIS WILL REQUIRE FOR ONE TO FIRST IMPLEMENT THE INFINITE CPS-BASED STACK LIBRARY!
	That one should: 
		0. Be written in TypeScript; 
		Include Types: 
		1. InfiniteStack; 
		2. CPSArray (this is, ultimately, a CPS version of JS array);

	As, CPS is (quite) time-costly to actually run (due to the stack unwinding [primary] + amount of stack usage + additional checks...),
		this sort of thing would be useful for applications where speed of little importance
			(that is: NOT things like apps/websites/interpreters, and so forth; Stuff like AOT-compilers, perhaps);
	
2. Write proper JSDoc documentation for all this stuff...
	DO NOT add the 'docs' copies into JSDoc, INSTEAD, just reference them...

3. Add various optimization data structures + utils + parser properties: 

	3.1. bufferize(process, size)(tree) - util

		Given a 'Tree', returns an array of values: 

			{
				index: number, 
				childNumber: number,
				value: any
			}

		This (ultimately) does THE SAME thing
			as the 'TreeStream', BUT without losing the children's Tree-information. 
		Unlike the 'TreeStream', this is intended as
			a more persistent data structure with faster, 
			and NON-LINEAR (important) access than TreeStream.
		
		Would return a 'NodeBuffer' (which is just a kind of an array); 
		Indexing an array could be (potentially) noticeably faster than walking through a Tree 
			(particularly so with the 'TreeStream'); 

		The 'index' is the index FROM THE BEGINNING of the buffer to the current Node. 
		The 'childNumber' is the number of children that come AFTER the current node. 
			Children are read between positions from 'index' to 'index + childNumber', 
				with each 'child' being checked for its own children
					(which, if nonzero, are excluded from the current children, and are instead counted as grandchildren). 
		
		The 'value' is the actual value at the index (note: being 'process'ed - this is intended for removing/keeping children, primarily); 

		If size is used, it will ONLY use this many items from the tree (up to the maximum amount - the rest of positions will be assigned to 'undefined'); 

	3.2. Add a 'state.size' property to the parsers. 
		This (ultimately) counts the number of items inside the tree.
		Can be used with 'bufferize': 

			bufferize((x) => x, pstate.size)(pstate.result)

	3.3. NestableStream: 

		A 'Stream', on which 'nested' has been implemented (id est WITHOUT copying) EFFICIENTLY! 
		This, ultimately, means prioritizing the elements of the 'Stream' over the actual NESTING. 

		NOTE: THE 'stream' here is a 'NavigableStream'; 

		The thing would: 

			1. Given a 'stream' (Stream) and a pair of functions 'inflate, deflate', create a 'NestableStream' [based on the current one, NOT COPYING] with: 
				1.1. .next(), which: 
					1.1.1. [if the 'stream.curr()' is not 'inflate(stream.curr()) == 1'], return 'stream.next()'; 
					1.1.2. [if the 'stream.curr()' IS 'inflate(stream.curr()) == 1'], return a new 'NavigableStream' with the same 'inflate', 'deflate' AND A NEW POSITION [NOTE: IT MUST be copied]; 
				1.2. '.curr', which is just a property for keeping track of the results of '.next()'; 
				1.3. 'isEnd' which would END THE STREAM [keep the locally-scoped boolean for this]!
					1.3.1. The boolean is actually altered on '.next()'; 

	3.4. isStream(x) functions: 
		For dealing with 'Stream's consisting of 'Stream's; 
		Allows one to identify a Stream, and handle it accordingly...; 
		Let there be different 'isStream' function (for different types of streams...);

		isLimitedStream, isNestableStream, isPositionalStream, et cetera

		The library has some already (needed for optimization purposes...);

	3.5. ProlongedStream; 
		The Stream-equivalent of 'prolong' utility; 
		'Concatenates' different streams into one; 
	
	3.6. TransformedStream: 
		The Stream-equivalent of 'transform' utility;
		Applies the given 'transform' on the 'Stream' on the 'per-element' basis.

	3.7. SubStream: 
		The Stream-equivalent of the 'find' utility (finds ALL occurences of the given 'position') - this [effectively], 
			gives a new Stream that has only the items with given 'position' (either property-function or a single element at that position, if any); 

		The property function has an 'i: Position' argument for THE POSITION!
	
	3.8. DelimitedStream: 
		The Stream-equivalent of 'delimited'; 
		Does THE SAME stuff as the 'delimited' function, but on Streams: 
			Skips the elements deemed 'delimiters', 
				'handle's the elements deemed 'non-delimiters'; 

	Note: the new object-oriented approach will enable better speed and lesser structure-copying (better memory use); 
		PLUS: one can have the 'Streams' in question working AS TREES without the necessity for creation of the actual TreeStream-s
			(as the recursive Stream-s more or less serve the same function - only problem is populating them with the appropriate kinds of objects); 

	3.9. TreeStream: create two versions; 

		The 'TreeStream' (currently) is the 'LL' pre-order tree traversal algorithm Stream-implementation; 
		There should be ANOTHER - the 'LR' post-order tree traversal; 

		Rename the 'TreeStream' to 'TreeStreamPre', and create an implemnetation for the 'TreeStreamPost'; 
		This is (particularly) useful for some types of interpreters; 

		The Pre  visits the node, then its children one-by-one starting from the beginning. 
		The Post visits first the children, only THEN the parent.

	3.10. recursiveTransform - a utility; 
		This recursively transforms all the sub-Stream-s within the given Stream; 
		It, effectively, frees the user from the necessity of writing the recursive functionality into their transformation themselves; 

	3.11. NestedlyTransformed - an object-oriented version of the 'recursiveTransform'; 

	3.12. Implement a 'PartialValidator': 
		This, ultimatly, works in THE SAME WAY as the 'PatternValidator' and 'PatternTokenizer' (GENERALIZE THEM TO A SINGLE FUNCTION ALREADY!)
		Gets the recursive structure with all the 'split' and 'inserted' bits; 
		The 'PartialValidator' would RETURN THE INFORMATION FOR INFERENCE OF CORRECT/INCORRECT PARTS! 
		[Which it does by 'numbering' particular portions of a given Pattern]; 
		This would allow for a greater ability to analyze/point-out the errors in the original input;

		Unlike plain PatternValidator, it would return ALL the possibly available error information, not just the stuff about the index of the "failed" check, or coverage; 

	3.13. Implement a 'level-by-level TreeStream': 

		It would get an initial given 'level' (tree root), walk through all of its '.children', 
			then walk each of the '.children' themselves as levels (one after another...), THEN descending lower...; 

	3.14. Add a 'HashClass'-implementation of 'MapClass'; 

		Basically, takes the 'hash' function (rough sketch) and returns a hash-table based off it...: 

			function HashTable (hash) {
				return function (values, keys = new Set(), default = null) {
					return function (x) {
						return !keys.size || keys.has(x) ? values[hash(x)] : default
					}
				}
			}

		Great for generalizing optimizations of tables/hashes/maps...

		Implement special  cases of this ALSO (PARTICULAR hash-functions...): 

			1. LengthHash: 

				This is excellent for string-identifiers; 
				Given a set of strings (THAT CAN BE UPDATED!),
					one has a hash function: 

						(string) => string.length

				The thing in question is (supposed) to map a given string to an array/collection 
					of other strings of equal length, then map in this collection (which has a different interface...);

				NOTE: ANYTHING with a '.length' property is usable with this;
				
			2. TreeHash (a kind of 'Hash', based off 'Tree'-s): 
				Basically, given an 'Indexed<Type>' (WITH A '.length'), and given an 'array-tree', one does (rough sketch, indexation): 

					function ArrayTreeHash (tree) {
						return function (x) {
							let current = tree
							for (let i = 0; i < x.length; ++i) current = current[x[i]]
							return current
						}
					}

				NOTE: the actual 'TreeHash' would be more general and use 'x' as a MULTIINDEX!
					(tree) => tree.index(x)
					BUT: for this, it'd require a more 'generalized' version (in particular, USE LOOPS INSTEAD OF '.reduce')

				This can be used with strings/

	3.15. __ALWAYS__ USE 'for'-loops INSTEAD OF '.reduce'!
		This makes code MUCH more general. 
		In particular, one does so with the 'Tree'-s; 
		It'd allow to (for instance) store identifiers, and getting them via 'loops'; 

		Excluding some few special cases (like 'childIndex'), walk through the project, 
			AND REPLACE un-place-ly '.reduce'-s with proper loops...

	3.16. Add a module SPECIFICALLY for working with strings/identifiers/Sequence-s (currently: the 'Indexed' interface); 

		In particular, functions/abstractions: 

			1. UniqueSequenceTree;

				This is an 'IndexMap'+'Tree'-implementation working like: 

					1. '.index' of a given 'string' (or another '.length'-having structure) BASICALLY, finds the first "unique" level it's on; 

						So, for instance, having a set: 

							{ ann, ant, ben }

						Would yield an IdentifierTree: 

							0   1 2
							a,b-n-n,t

						This (basically) uses recursive objects + indexation
						(
							ant is found in 3 iterations; 
							an is found in 2 iterations; 
							'ben' is found in 1 iteration (only 'b' is stored);
						)

				Note: this implements a HashMap's 'hash'; 
				This is VERY good for frequent accesses to THE SAME value; 

			2. BinarySearchTree; 

				Same as 'UniqueSequenceTree', BUT it implements a Binary Search Tree.
				It works based on a provided comparison (a very rough indexation sketch): 

					function BinarySearchTree(tree, comparison) {
						return function (x) {
							let current = tree
							let greater
							while (current.length) current = current[+comparison(current, x)]
							return current.value
						}
					}
				
				NOTE: with (x, y) => x > y, can be used with identifiers; 

			3. shorten(names); 
				Given a sequence of "names" (strings/sequences),
					and a 'comparison' predicate for each of its elements,
						it would implement a name-shortening algorithm, 
							that would preserve the name uniqueness;
				
				The return value is an IndexMap; 

			4. renameable(names);
				Given an IndexMap of names (which could come from, for instance, 'shorten'), 
					the method: 

					1. Re-orders;
					2. Creates new name-map entries;

				In a fashion that would allow straightforward implementation of a sequential "exact replacement algorithm" based on the output: 

					1. Loop through a list of name-maps; 
						2. [In the loop] Rename current encounters of a name with its mapped value;	
					
				There are 2 operations that may be necessary: 

					1. creation of temp-names (when collisions in present names are far too high to re-order);
					2. re-order; 
				
				The algorithm for the 'renameable' function: 

					0. Keep the cached (met) names in a 'Set'; 
					1. Loop through the 'names' given: 
						1.0. If the name is in the cached Set, continue; 
						1.1. If the current 'value' of the 'name' is already present amongst 'keys' (another loop): 
							1.1.1. put the keys in question BEFORE the current value;
							1.1.2. '.swap' the two indexes;
							1.1.3. go one position back (because now one needs to check the "others" now); 
							1.1.4. cache the current amongst the checked names in a 'Set', (so that one doesn't get into an infinite loop);

	3.17. Replace the 'Tree' methods with in-place algorithms (not what this currently is...); 
		The 'copying' for Tree-s should be a WHOLE SEPARATE thing with ITS OWN module; 
		NOTE: the 'copying' in question occurs in methods 'MultValueTree' and 'RecursiveArrayTree'; 

		Namely: 

			1. RecursiveCopy:

				This is a method that deals with the 'ConstructibleTree's interface (basically, trees that can also be [generally] modified...);
				It creates a new such tree based off the current one; 

				Uses a general interface to copy arbitrary trees; 
				There has to be a 'flatCopy(): Tree' function for a given tree
					(which, repeated recursively, would yield a new tree, 
						and allow to preserve the reference to the underlying children WITHOUT
							preserving the reference to the tree itself...);

				This would be a 'FlatCopiableTree'; 
	
	3.18. Create a 'ModifiableStream' interface;

		It is (basically) a Stream, into which things can be INSERTED, whilst it is iterated. 
		Id est: 

			// ...
			input.next()
			input.insert(X) // calls another 'input.next()'; input.curr() now is 'X'; The thing RETURNS the result of the 'input.next()';

		Implement various different kinds of ModifiableStream-s; 

		1. A 'ModifiableTreeStream' "interface" (set of TreeStream-related implementations) would be a 'ConstructibleTree';

			There'd be different ModifiableTreeStream-s; 
			Their '.insert' would be based off how the tree was visited: 

				1. pre-order: it adds a NEW FIRST child to the current tree's node;
				2. post-order:
					1. IF current node has a parent already, adds a new parent to it
						(the current node; ID EST, adds a new CHILD to the current parent, and makes it the parent of the current node...)
					2. Otherwise, adds a node that is a FIRST CHILD of the current one; 
			
			There would also be some 'special' methods on 'TreeModifier', INDEPENDENT of the 'ModifiableTreeStream'-s [which would work with the TreeContext-s themselves]: 
			
				1. "insertSibling", which would insert a next sibling of the current element; 
				2. "insertLast", which would insert a child TO THE END of the tree's '.children';
				3. "insertChild", which would insert a child at a given index; 
				4. 'prependSibling', which would add a sibling BEFORE the current child; 

				PROBLEM: this sort of thing would OCCASIONALLY INVALIDATE the 'last' index; 
					It would have to be re-computed in such cases; 

			NOTE: there'd be a special new "class" of objects called 'TreeModifier' (analogous to 'TreeWalker'); 
				NOTE: Due to how the 'multi-index' of a 'Tree' would be "contained" within the 'TreeWalker',
					yet it would STILL need to be accessed by the 'TreeModifier' [in Stream Contexts...], 
						one might NEED to unite the two...; 

					IDEA: TreeIndexContext;
						This, basically, contains a triple: 

							{
								index: MultiIndex
								walker: TreeWalker
								modifier: TreeModifier
							}

						And the TreeWalker, TreeModifier, would be 'bound' to the current one (that is, they'd be taking an argument of 'multindex');

			The 'TreeModifier' implementations would HAVE to have a sort of "Modifiable" Tree (which is a special case of a 'Tree'); 
			A 'ChildrenTree' (Tree with '.children') is a GREAT fit for it...; 

		2. A 'ModifiablePositionalStream' would be a wrapper around another 'PositionalStream', 
			which would have a map of 'Positions', into which things were 'inserted', and would return new stuff accordingly...
			It is ALSO a 'PositionalStream'; 

			NOTE: for this stuff to WORK generally, one needs to define an 'AdditivePosition',
				one for which the 'skip(stream: PositionalStream, plus: Position)', or 'add(stream: PositionalStream, plus: Position)', 
					would exist. 

					'Number' special case of 'add(...)': 
						(a, b) => a + b
					
					Basically, just "goes forward"; 
					Similarly, there'd be a 'backout(stream: PositionalStream, plus: Position)' [or call it 'return'] method for these; 

					For numbers, definition is: 
						(a, b) => a - b

			The ModifiablePositionalStream would be a PositionalStream ALSO, which would permit one to 
				"stack them up" on top of one another (which is good for semantics separation...). 

		3. A 'ModifiableSplicableStream' would be a 'ModifiableStream' for 'Splicable'-s: 

			A 'Splicable' is an interface (extension of 'Indexed') with an Array-like .splice(index: number, toDelete: number, ...items: any) interface;
			Arrays are splice-ables; 

			The implementation would (basically) do: 

				{
					...InputStream(splicable),
					insert: function (X) {
						this.input.splice(this.pos, 0, X)
					}
				}
	
	3.19. MORE WORK on the 'IndexMap'; 
		
		Things to do: 
			1. add a '.swap' method (for swapping two positions); 

	3.20. MORE work on the 'NavigableStream-s'!

		Currently, these DON'T HAVE AN OPTION TO navigate "backwards" via a predicate; 
		Which is disappointing; 

		There should be a SEPARATE SIGNATURE for this: a predicate on its own NO LONGER suffices; 
		Call it 'PredicatePosition': 

			{
				predicate: SummatFunction, 
				direction?: boolean
			}

		With 'true' (the default, if missing) designating 'forward'
			and 'prev' designating 'Backwards'; 
		
		One will ALSO need to: 

			1. Create a `BacktrackableStream` interface. 
				It is one that is `Navigable & Reversible`;
				A BacktrackableStream, then would be used for the proper re-definition of the 'inputStreamNavigate'; 

	3.21. CREATE A LOT OF Proxy-based OPTIMIZATION STRUCTURES!
		These are MIGHTY! [allow to save memory, and so forth...]; 
		IDEA: maybe, even create a library for these...; 

	3.22. IDEA: benchmark, and, if it seems worth it (that is, the Object-oriented version is REALLY faster/less-memory-needy/not-too-"heavy"): 

		1. LIGHTEN the library by removing the functional API completely, replacing it with: 	
			1.1. Object-oriented alternatives (more or less outlined already);
			1.2. The 'consume' function for transforming given 'Stream'-s into 'Collection'-s (to make things simpler...);
		2. DO EVERYTHING ELSE ONLY after this is finished (either functional STAYS, or it gets replaced....);

		The fundamental issue with the 'utils' is that they provide (quite literally) NO value [besides semantic], 
			whilst requiring the user to: 

			1. Spend additional O(n) time and space on operations for representation in a 'nicer' data structure...
				(which, with introduction of Object-Oriented API really isn't necessary anymore)
		
		Certain utilities, however, would stay. 
		This (primarily) refers to the ones that actually might have (some) efficiency implications. 
		To keep: 
			
			1. skip - this doesn't work with ANY kinds of data structures (so, it doesn't have an 'output' per-se); 
			2. consume - basic thing (needed FOR SAVING the given Stream desirably [without the overhead of having to reverse it prior]); 
			3. has - doesn't have a data-structure output; 
		
	3.23. Expand on the 'Position' type further;

		Allow for creation of more "exotic" types;
		Example: 

			"go up to nearest point in the past defined by predicate 'P', then another 5 positions", 

		should be something like: 

			[P, 5] // with 'P.direction = false'; 
		
		Allow "nesting" positions like so, create a proper PositionEvaluator (current thing is VERY limited); 

		The 'RelativePositionEvaluatorStream' would (ultimately) create a 'Stream' of values, defined by this "sequence"
			of Position-s (call it 'PositionSequence = Position[]'), and which would be entirely relative to one another; 

		The 'AbsolutePositionEvaluatorStream' would (similarly) interpret a sequence of 'Position's,
			but relative to the initial Stream (not one another).
		
		Then, GENERALIZE THIS to a 'PortionPosition' [which is the pair '[Position, Position]' used in 'LimitedStream'],
			to also use this with 'LimitedStream';

		So, 'PositionSequence = (Position | [Position, Position])[]' will define a new Stream based of a given one
			via the 'AbsolutePositionEvaluatorStream' and 'RelativePositionEvaluatorStream'; 

	3.24. MergeStream - equivalent of the 'merge' util; 
		As per 3.24 - replace functional API with OOP; 

	3.25. SplitStream - generalization of 'extract' util (as per 3.24.), reverse of 'MergeStream';

		Based off a given set of predicates (by default, if set size is 1: {P}, uses 2: {P, !P}),
			it defines a set of non-interlocking streams; 
		The predicates are interpreted to be 'greedy', in the sense that each will work to increase its Stream's size
			FOR AS LONG AS IT CAN.
	
	3.26. RELAX overly demanding interface and types definitions/requirements;
		Example: inputStreamCopy, inputStreamNavigate; 

			These do not NEED to have all the parts of the 'InputStream' definition (even though, they are originally implemented to work with it);
			RE-DEFINE them...;
		

	3.27. Make all the 'Stream'-s implementations out there __ITERABLE__! 
			With the 'default' Iterator being given as a 'streamIterator' constructor;

	
4. Dependency management: 

	4.1. Take the 'Summat.ts' out into a separate npm package;
	4.2. Take the 'Pointer.ts' out into a separate npm package (IF ever come down to not-needing it in this one...)
		4.2.1. Take it out ANYWAY, just not in 0.3. IF it's needed at that stage...; 
		4.2.2. This would depend on 'one.js' [AFTER adding TypeScript to it...]; 
	4.3. Create a 'proxy-op' library SPECIFICALLY for various optimizations based on Proxy-functions on different types/kinds of objects;	
		4.3.1. These (sometimes) can help GREATELY reduce memory-consumption; Example: the Slicer; Include those there...; 
	4.4. Add generics + proper 'lower-level' (more "fractured") types to the ''; 