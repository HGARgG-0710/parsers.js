[GENERAL]
1. Check if this works with Deno; 	

[v0.3]

NOTE: nope, the version is NOT finished. 

	-5. More conditional functions, 'is'-functions based off interfaces; 

		Many are missing appropriate functions for checking presence of properties...; 

	-4. CHECK EXPORTS FOR CORRECTNESS! 
		Primarily concerns missing exports in the 'Parser/' immidiate files; 


	-3.1. PROBLEM : with replacement of 'basicStreamInitGetter'; 

		The new 'StreamCurrGetter' has a BAD setter! 
		ID EST, the 'initGetter' and the 'currGetter' CONFLICT with one another...; 

		It has to have a mechanism of determining WHEN to use which ...; 

		PROBLEM WITH IT, HOWEVER, IS, that IN ORDER TO DECIDE, it has to KEEP IN SYNC with the calls of '.next', 
			or have '.next' modify its state!

		Which is extremely bad and breaks the modularity...; 

		Need to consider re-structuring majorly AGAIN; 

		Idea [for a solution]: 
		
			1. Create a single GeneralIterationHandler, creating an object with: 

				1.1. baseCurr; 
				1.2. baseIter [{ baseIter(); return baseCurr() } = baseNext()]; 
				1.3. next; [which works off 'baseCurr+baseIter']; 
				1.4. curr: 
					which works off a: 

						1. explicit setter/getter (ex.: TreeStream); 
						2. init getter (for the first value, DEFAULTS to the general getter); 
						3. general getter (ONLY after having called '.next' ONCE, and 'first' value was exhausted); 

						ALSO, it's possible to cache the values from the '.next'/'.prev'; 

				NOTE: that the first time that the '.next' is called and 'isStart' ARE THE SAME!
					Thus, it'll actually be a GENERAL TEMPLATE for the library Stream-s;

					They would all contain information regarding: 

						1. next, baseIter; 
						2. isEnd, isStart; 
						3. curr, baseCurr;
						4. isEndCurr; 

				A BIT OF A HACK: for simplicity, and universality, the library would have 2 reserved truthy values for '.isStart': 

					VALUE-A. 1; 
					VALUE-B. true; 

				VALUE-A is used ONLY when the '.curr' is STILL UNINITIALIZED, 
					whereas 'VALUE-B' is used for cases of SECONDARY initialization [ex: '.rewind' or '.prev']; 
				
				THESE TWO CONSTANTS would be defined in a separate file [and exported]; 

				Thus, the workflow: 

					1. curr: 
						1.1. properties: 
							1.1.1. .realCur
							1.1.2. .isStart = 1; 
							1.1.3. .initCurr()
							1.1.4. .currGetter()
						1.2. workflow [get]: 
							1.2.1. IF isStart === 1, 
								1.2.1.1. this.realCurr = this.initCurr() // 'initCurr' is 'currGetter', unless alternative is provided; 
								1.2.1.2. this.isStart = true
								1.2.1.3. return this.realCurr
							1.2.2. ELSE 
								1.2.2.1. IF this.currGetter != null and !.isStart: 
									1.2.2.1.1. return this.currGetter()
								1.2.2.2. ELSE: 
									1.2.2.2.1. reutrn this.realCurr
						1.3. workflow [set; 'value']: 
							1.3.1. this.realCurr = value
					2. next/prev: 
						2.1. properties: 
							2.1.1. isEnd/isStart (bound, boolean); 
							2.1.2. baseIter (baseIterNext, baseIterPrev); 
						2.2. workflow [usage]: 
							2.2.1. [WRAPPED in the 'isEnd/isStart' check - PREVIOUSLY DONE]; 
								2.2.1.1. const curr = this.curr
								2.2.1.2. this.baseIter(); 
								2.2.1.3. this.curr = this.baseCurr(); 
								2.2.1.4. return curr

				Props to add: 

					1. baseIter; 
					2. initCurr; 
					3. baseCurr; 
				
				Props to delete:
				
					1. metFirst

	-3. PROBLEM: basicStreamInitGetter: 

		This DOESN'T work as intended; 
		THE WHOLE PURPOSE of the new 'StreamCurrGetter' definition is so that user can 
			RE-DIRECT (id est, implicitly propagate by referencing) the first call to '.curr' AND USE IT 
				in computations; 

		The '.baseNext' system (.isEnd-check + .baseNext-method for iteration) is (yet again) FAR too simple for 
			cases that work as 'wrapper-Streams' over other Streams; 
			These are: 

			1. TransformedStream; 
			2. StreamTokenizer; 
			3. NestedStream; 

		The 'basicStreamInitGetter' is SUPPOSED to work like the following: 

			1. Get the underlying stream's .curr (this.input.curr); 
			2. Run the '.baseCurr' (???) function on 'this.input.curr'; 
			3. Return the result of '.baseCurr'; 
		
		The key issue here is that the 'baseCurr' function (currently undefined), which is 
			SUPPOSED to be doing all the things that the corresponding '.baseNext' is currently doing, BUT, 
				without necessarily doing the 'this.input.next()'; 

		However, as this is SUCH a simple relation, there's really no need to introduce any structural alternative
			(in the sense, that, this is NOT a general construction); 
		
		THEREFORE [refactoring algorithm]: 

			1. Create 'baseCurr' based off prev. 'baseNext'; 
			2. Use 'baseCurr' for the re-definition [compactification] of 'baseNext'; 
			3. Use 'baseCurr' function to define the 'initCurrGetter'-s; 

		But then, comes the question of cleanness - this is all... pretty ugly currently; 

			The "re-modularization" pretty much falls apart once one starts to pack files with LOTS of different "related" methods; 
		
		CONCLUSION: one should re-distribute the 'next', 'prev' and ALL the other stuff BACK to their origin-sourcefiles...;

			AND do the same for the "abstract" classes (that are really just interfaces with utils - Rewindable, Finishable, and so forth...); 

	-1. [Think how to] SEPARATE the 'Base'- and 'Basic'-based 'Stream's (as the 'Base' requirements, are, quite honestly, OPTIONAL); 
		-1.1. At the same time, the 'Base' references the IMPLEMENTATION DETAILS, BUT, 
			it is ALSO used throughout the library to solve the 'isEnd'-definition issue; 

			ULTIMATELY, separate the 'used' (Base) and 'non-used' (Basic) interfaces (difference being all in implementation); 

		-1.2. Perhaps...; 

			Move the 'BaseStream' interfaces INTO THE "main" 'Stream/interfaces.ts'? 
			[It is USED practically everywhere and it's not specific to the BasicStream]; 

				In accordance with the new changes: 

					-1.2.1. All the implementation-related stuff is handled by the 'StreamIterationHandler' and 'StreamClass' thingies; 
						Thus, the 'Base' things VANISH COMPLETELY, and the remainder (that ends up being useful) gets ABSORBED into the 'StreamClass'; 

							Sketch: 

								1. Create 'Conditional' and 'Forced' property-types (with 'Conditional' being used for the "typical"/relaxed StreamClassInstance interface); 
									1.1. Example: 'ForcedPrevable - prev(): Type' and 'ConditionalPrevable - prev?(): Type'; 
								2. Put them all into 'StreamIterationHandler/interfaces.ts'; 
								3. The implementations that already use the 'StreamClass' must ALL use the interfaces from the 'StreamIterationHandler', and their own interfaces SHOULD BE THE SPECIAL CASES!
								4. The parts of the implementations' interfaces that are NOT coverable by the 'StreamClass' interfaces, must also use the 'basic ones'; 
									4.1. The 'basic' interfaces are those that can be directly employed by the user for creation of their own low-level implementations of Streams: 
										4.1.1. Nextable; 
										4.1.2. Prevable (ONLY Forced, NOT Conditional - this is inside the 'StreamIterationHandler'); 
										4.1.3. Currable; 
										4.1.4. Endable; 
										4.1.5. Started (There is 'StatefulStarted' - with 1 | boolean, and regular 'Started' - with JUST boolean); 
										4.1.6. .navigate, .rewind., .finish, .limit, all the others; 

								NOTE: parts that ARE covered by implementation-interfaces: 
									1. 'Conditional' stuff; 
									2. 'BaseIterableNext'/'BaseIterablePrev'; 
									3. 'IsCurrEndable'/'IsCurrStartable'; 
									4. 'BaseCurrable' (.baseCurr, mandatory); 
									5. 'CurrGetterHaving' (.currGetter, conditional); 
									6. 'RealCurred' (.realCurr, mandatory); 
									7. 'InitCurred' (.initCurr, conditional); 
									8. 'StatefulStarted' (1 | boolean version of 'Started'); 

	1. THE BENCHMARK HATH SPOKEN! 

		Based off a (very) approximate heuristic of 'consume' (which was) 'the fastest/simplest' of them all...; 
		The simple 'iteration' approach IS (quite a bit) faster; 
	
		1. 3.3-3.5
		2. 3.19, 3.20
		3. 3.7, 3.8
		4. 3.23. 
		
		Utilities to keep: 
			
			1. skip - this doesn't work with ANY kinds of data structures (so, it doesn't have an 'output' per-se); 
			2. array - basic thing (needed FOR SAVING the given Stream desirably [without the overhead of having to reverse it prior]); 
			3. has - doesn't have a data-structure output; 
			4. nested - it's far too specific (because SOMETIMES, one may desire NOT the 'partitioned' NestedStream [though, that is very frequently the case], BUT the 'whole' thing as a Collection); 

A. testing [1. Create list of modules to be tested]; 
B. documentation (change/fix it...); 
C. rewrite the CHANGELOG [too much has been altered since the "initial" v0.3]; 

[v0.4]

1. STACK! 
	The library is not too stack heavy, BUT it does have an (ultimate) stack-limitation
		when working with NestableStream-s and the 'nested' util (generally, anything that is NON-FLAT);
	This is very much impossible to solve on its own; 

	SOLUTION: use the CPS style. 
		Re-implement library (whilst keeping the non-CPS version) in CPS, 
		with an infinite 'stack'; 

	! THIS WILL REQUIRE FOR ONE TO FIRST IMPLEMENT THE INFINITE CPS-BASED STACK LIBRARY!
	That one should: 
		0. Be written in TypeScript; 
		Include Types: 
		1. InfiniteStack; 
		2. CPSArray (this is, ultimately, a CPS version of JS array);

	As, CPS is (quite) time-costly to actually run (due to the stack unwinding [primary] + amount of stack usage + additional checks...),
		this sort of thing would be useful for applications where speed of little importance
			(that is: NOT things like apps/websites/interpreters, and so forth; Stuff like AOT-compilers, perhaps);
	
2. Write proper JSDoc documentation for all this stuff...
	DO NOT add the 'docs' copies into JSDoc, INSTEAD, just reference them...

3. Add various optimization data structures + utils + parser properties: 

	3.1. bufferize(process, size)(tree) - util

		Given a 'Tree', returns an array of values: 

			{
				index: number, 
				childNumber: number,
				value: any
			}

		This (ultimately) does THE SAME thing
			as the 'TreeStream', BUT without losing the children's Tree-information. 
		Unlike the 'TreeStream', this is intended as
			a more persistent data structure with faster, 
			and NON-LINEAR (important) access than TreeStream.
		
		Would return a 'NodeBuffer' (which is just a kind of an array); 
		Indexing an array could be (potentially) noticeably faster than walking through a Tree 
			(particularly so with the 'TreeStream'); 

		The 'index' is the index FROM THE BEGINNING of the buffer to the current Node. 
		The 'childNumber' is the number of children that come AFTER the current node. 
			Children are read between positions from 'index' to 'index + childNumber', 
				with each 'child' being checked for its own children
					(which, if nonzero, are excluded from the current children, and are instead counted as grandchildren). 
		
		The 'value' is the actual value at the index (note: being 'process'ed - this is intended for removing/keeping children, primarily); 

		If size is used, it will ONLY use this many items from the tree (up to the maximum amount - the rest of positions will be assigned to 'undefined'); 

	3.2. Add a 'state.size' property to the parsers. 
		This (ultimately) counts the number of items inside the tree.
		Can be used with 'bufferize': 

			bufferize((x) => x, pstate.size)(pstate.result)

	3.3. ProlongedStream; 
		The Stream-equivalent of 'prolong' utility; 
		'Concatenates' different streams into one; 

	3.4. SubStream: 
		The Stream-equivalent of the 'find' utility (finds ALL occurences of the given 'position') - this [effectively], 
			gives a new Stream that has only the items with given 'position' (either property-function or a single element at that position, if any); 

		The property function has an 'i: Position' argument for THE POSITION!
	
	3.5. DelimitedStream: 
		The Stream-equivalent of 'delimited'; 
		Does THE SAME stuff as the 'delimited' function, but on Streams: 
			Skips the elements deemed 'delimiters', 
				'handle's the elements deemed 'non-delimiters'; 

	Note: the new object-oriented approach will enable better speed and lesser structure-copying (better memory use); 
		PLUS: one can have the 'Streams' in question working AS TREES without the necessity for creation of the actual TreeStream-s
			(as the recursive Stream-s more or less serve the same function - only problem is populating them with the appropriate kinds of objects); 

	3.6. TreeStream: create two versions; 

		The 'TreeStream' (currently) is the 'LL' pre-order tree traversal algorithm Stream-implementation; 
		There should be ANOTHER - the 'LR' post-order tree traversal; 

		Rename the 'TreeStream' to 'TreeStreamPre', and create an implemnetation for the 'TreeStreamPost'; 
		This is (particularly) useful for some types of interpreters; 

		The Pre  visits the node, then its children one-by-one starting from the beginning. 
		The Post visits first the children, only THEN the parent.

	3.7. recursiveTransform - a utility; 
		This recursively transforms all the sub-Stream-s within the given Stream; 
		It, effectively, frees the user from the necessity of writing the recursive functionality into their transformation themselves; 

	3.8. NestedlyTransformed - an object-oriented version of the 'recursiveTransform'; 

	3.9. Implement a 'PartialValidator': 
		This, ultimatly, works in THE SAME WAY as the 'PatternValidator' and 'PatternTokenizer' (GENERALIZE THEM TO A SINGLE FUNCTION ALREADY!)
		Gets the recursive structure with all the 'split' and 'inserted' bits; 
		The 'PartialValidator' would RETURN THE INFORMATION FOR INFERENCE OF CORRECT/INCORRECT PARTS! 
		[Which it does by 'numbering' particular portions of a given Pattern]; 
		This would allow for a greater ability to analyze/point-out the errors in the original input;

		Unlike plain PatternValidator, it would return ALL the possibly available error information, not just the stuff about the index of the "failed" check, or coverage; 

	3.10. Implement a 'level-by-level TreeStream': 

		It would get an initial given 'level' (tree root), walk through all of its '.children', 
			then walk each of the '.children' themselves as levels (one after another...), THEN descending lower...; 

	3.11. Add a 'HashClass'-implementation of 'MapClass'; 

		Basically, takes the 'hash' function (rough sketch) and returns a hash-table based off it...: 

			function HashTable (hash) {
				return function (values, keys = new Set(), default = null) {
					return function (x) {
						return !keys.size || keys.has(x) ? values[hash(x)] : default
					}
				}
			}

		Great for generalizing optimizations of tables/hashes/maps...

		Implement special  cases of this ALSO (PARTICULAR hash-functions...): 

			1. LengthHash: 

				This is excellent for string-identifiers; 
				Given a set of strings (THAT CAN BE UPDATED!),
					one has a hash function: 

						(string) => string.length

				The thing in question is (supposed) to map a given string to an array/collection 
					of other strings of equal length, then map in this collection (which has a different interface...);

				NOTE: ANYTHING with a '.length' property is usable with this;
				
			2. TreeHash (a kind of 'Hash', based off 'Tree'-s): 
				Basically, given an 'Indexed<Type>' (WITH A '.length'), and given an 'array-tree', one does (rough sketch, indexation): 

					function ArrayTreeHash (tree) {
						return function (x) {
							let current = tree
							for (let i = 0; i < x.length; ++i) current = current[x[i]]
							return current
						}
					}

				NOTE: the actual 'TreeHash' would be more general and use 'x' as a MULTIINDEX!
					(tree) => tree.index(x)
					BUT: for this, it'd require a more 'generalized' version (in particular, USE LOOPS INSTEAD OF '.reduce')

				This can be used with strings/

	3.12. __ALWAYS__ USE 'for'-loops INSTEAD OF '.reduce'!
		This makes code MUCH more general. 
		In particular, one does so with the 'Tree'-s; 
		It'd allow to (for instance) store identifiers, and getting them via 'loops'; 

		Excluding some few special cases (like 'childIndex'), walk through the project, 
			AND REPLACE un-place-ly '.reduce'-s with proper loops...

	3.13. Add a module SPECIFICALLY for working with strings/identifiers/Sequence-s (currently: the 'Indexed' interface); 

		In particular, functions/abstractions: 

			1. UniqueSequenceTree;

				This is an 'IndexMap'+'Tree'-implementation working like: 

					1. '.index' of a given 'string' (or another '.length'-having structure) BASICALLY, finds the first "unique" level it's on; 

						So, for instance, having a set: 

							{ ann, ant, ben }

						Would yield an IdentifierTree: 

							0   1 2
							a,b-n-n,t

						This (basically) uses recursive objects + indexation
						(
							ant is found in 3 iterations; 
							an is found in 2 iterations; 
							'ben' is found in 1 iteration (only 'b' is stored);
						)

				Note: this implements a HashMap's 'hash'; 
				This is VERY good for frequent accesses to THE SAME value; 

			2. BinarySearchTree; 

				Same as 'UniqueSequenceTree', BUT it implements a Binary Search Tree.
				It works based on a provided comparison (a very rough indexation sketch): 

					function BinarySearchTree(tree, comparison) {
						return function (x) {
							let current = tree
							let greater
							while (current.length) current = current[+comparison(current, x)]
							return current.value
						}
					}
				
				NOTE: with (x, y) => x > y, can be used with identifiers; 

			3. shorten(names); 
				Given a sequence of "names" (strings/sequences),
					and a 'comparison' predicate for each of its elements,
						it would implement a name-shortening algorithm, 
							that would preserve the name uniqueness;
				
				The return value is an IndexMap; 

			4. renameable(names);
				Given an IndexMap of names (which could come from, for instance, 'shorten'), 
					the method: 

					1. Re-orders;
					2. Creates new name-map entries;

				In a fashion that would allow straightforward implementation of a sequential "exact replacement algorithm" based on the output: 

					1. Loop through a list of name-maps; 
						2. [In the loop] Rename current encounters of a name with its mapped value;	
					
				There are 2 operations that may be necessary: 

					1. creation of temp-names (when collisions in present names are far too high to re-order);
					2. re-order; 
				
				The algorithm for the 'renameable' function: 

					0. Keep the cached (met) names in a 'Set'; 
					1. Loop through the 'names' given: 
						1.0. If the name is in the cached Set, continue; 
						1.1. If the current 'value' of the 'name' is already present amongst 'keys' (another loop): 
							1.1.1. put the keys in question BEFORE the current value;
							1.1.2. '.swap' the two indexes;
							1.1.3. go one position back (because now one needs to check the "others" now); 
							1.1.4. cache the current amongst the checked names in a 'Set', (so that one doesn't get into an infinite loop);

	3.14. Replace the 'Tree' methods with in-place algorithms (not what this currently is...); 
		The 'copying' for Tree-s should be a WHOLE SEPARATE thing with ITS OWN module; 
		NOTE: the 'copying' in question occurs in methods 'MultValueTree' and 'RecursiveArrayTree'; 

		Namely: 

			1. RecursiveCopy:

				This is a method that deals with the 'ConstructibleTree's interface (basically, trees that can also be [generally] modified...);
				It creates a new such tree based off the current one; 

				Uses a general interface to copy arbitrary trees; 
				There has to be a 'flatCopy(): Tree' function for a given tree
					(which, repeated recursively, would yield a new tree, 
						and allow to preserve the reference to the underlying children WITHOUT
							preserving the reference to the tree itself...);

				This would be a 'FlatCopiableTree'; 
	
	3.15. Create a 'ModifiableStream' interface;

		It is (basically) a Stream, into which things can be INSERTED, whilst it is iterated. 
		Id est: 

			// ...
			input.next()
			input.insert(X) // calls another 'input.next()'; input.curr() now is 'X'; The thing RETURNS the result of the 'input.next()';

		Implement various different kinds of ModifiableStream-s; 

		1. A 'ModifiableTreeStream' "interface" (set of TreeStream-related implementations) would be a 'ConstructibleTree';

			There'd be different ModifiableTreeStream-s; 
			Their '.insert' would be based off how the tree was visited: 

				1. pre-order: it adds a NEW FIRST child to the current tree's node;
				2. post-order:
					1. IF current node has a parent already, adds a new parent to it
						(the current node; ID EST, adds a new CHILD to the current parent, and makes it the parent of the current node...)
					2. Otherwise, adds a node that is a FIRST CHILD of the current one; 
			
			There would also be some 'special' methods on 'TreeModifier', INDEPENDENT of the 'ModifiableTreeStream'-s [which would work with the TreeContext-s themselves]: 
			
				1. "insertSibling", which would insert a next sibling of the current element; 
				2. "insertLast", which would insert a child TO THE END of the tree's '.children';
				3. "insertChild", which would insert a child at a given index; 
				4. 'prependSibling', which would add a sibling BEFORE the current child; 

				PROBLEM: this sort of thing would OCCASIONALLY INVALIDATE the 'last' index; 
					It would have to be re-computed in such cases; 

			NOTE: there'd be a special new "class" of objects called 'TreeModifier' (analogous to 'TreeWalker'); 
				NOTE: Due to how the 'multi-index' of a 'Tree' would be "contained" within the 'TreeWalker',
					yet it would STILL need to be accessed by the 'TreeModifier' [in Stream Contexts...], 
						one might NEED to unite the two...; 

					IDEA: TreeIndexContext;
						This, basically, contains a triple: 

							{
								index: MultiIndex
								walker: TreeWalker
								modifier: TreeModifier
							}

						And the TreeWalker, TreeModifier, would be 'bound' to the current one (that is, they'd be taking an argument of 'multindex');

			The 'TreeModifier' implementations would HAVE to have a sort of "Modifiable" Tree (which is a special case of a 'Tree'); 
			A 'ChildrenTree' (Tree with '.children') is a GREAT fit for it...; 

		2. A 'ModifiablePositionalStream' would be a wrapper around another 'PositionalStream', 
			which would have a map of 'Positions', into which things were 'inserted', and would return new stuff accordingly...
			It is ALSO a 'PositionalStream'; 

			NOTE: for this stuff to WORK generally, one needs to define an 'AdditivePosition',
				one for which the 'skip(stream: PositionalStream, plus: Position)', or 'add(stream: PositionalStream, plus: Position)', 
					would exist. 

					'Number' special case of 'add(...)': 
						(a, b) => a + b
					
					Basically, just "goes forward"; 
					Similarly, there'd be a 'backout(stream: PositionalStream, plus: Position)' [or call it 'return'] method for these; 

					For numbers, definition is: 
						(a, b) => a - b

			The ModifiablePositionalStream would be a PositionalStream ALSO, which would permit one to 
				"stack them up" on top of one another (which is good for semantics separation...). 

		3. A 'ModifiableSplicableStream' would be a 'ModifiableStream' for 'Splicable'-s: 

			A 'Splicable' is an interface (extension of 'Indexed') with an Array-like .splice(index: number, toDelete: number, ...items: any) interface;
			Arrays are splice-ables; 

			The implementation would (basically) do: 

				{
					...InputStream(splicable),
					insert: function (X) {
						this.input.splice(this.pos, 0, X)
					}
				}
	
	3.16. MORE WORK on the 'IndexMap'; 
		
		Things to do: 
			1. add a '.swap' method (for swapping two positions); 

	3.17. CREATE A LOT OF Proxy-based OPTIMIZATION STRUCTURES!
		These are MIGHTY! [allow to save memory, and so forth...]; 
		IDEA: maybe, even create a library for these...; 
		
	3.18. Expand on the 'Position' type further;

		Allow for creation of more "exotic" types;
		Example: 

			"go up to nearest point in the past defined by predicate 'P', then another 5 positions", 

		should be something like: 

			[P, 5] // with 'P.direction = false'; 
		
		Allow "nesting" positions like so, create a proper PositionEvaluator (current thing is VERY limited); 

		The 'RelativePositionEvaluatorStream' would (ultimately) create a 'Stream' of values, defined by this "sequence"
			of Position-s (call it 'PositionSequence = Position[]'), and which would be entirely relative to one another; 

		The 'AbsolutePositionEvaluatorStream' would (similarly) interpret a sequence of 'Position's,
			but relative to the initial Stream (not one another).
		
		Then, GENERALIZE THIS to a 'PortionPosition' [which is the pair '[Position, Position]' used in 'LimitedStream'],
			to also use this with 'LimitedStream';

		So, 'PositionSequence = (Position | [Position, Position])[]' will define a new Stream based of a given one
			via the 'AbsolutePositionEvaluatorStream' and 'RelativePositionEvaluatorStream'; 

	3.19. MergeStream - equivalent of the 'merge' util; 
		As per 3.24 - replace functional API with OOP; 

	3.20. SplitStream - generalization of 'extract' util (as per 3.24.), reverse of 'MergeStream';

		Based off a given set of predicates (by default, if set size is 1: {P}, uses 2: {P, !P}),
			it defines a set of non-interlocking streams; 
		The predicates are interpreted to be 'greedy', in the sense that each will work to increase its Stream's size
			FOR AS LONG AS IT CAN.
	
	3.21. RELAX overly demanding interface and types definitions/requirements;
		Example: inputStreamCopy, inputStreamNavigate; 

			These do not NEED to have all the parts of the 'InputStream' definition (even though they are originally implemented to work with it);
			RE-DEFINE them...;

	3.22. [Idea?] Create an error-handling API for the 'v0.4';
		Create means of: 

			1. Stacking different levels of exceptions (the 'try-catch' blocks); 
			2. Assigning relevant debug information to them;

		This is (primarily) for the development process of the parsers; 
		
		Define a Catcher [rough sketch]: 

			function Catcher (info: DebugInfo, logger: Function) {
				return function (thing: Function, thisArg: any, args: any) {
					try {
						thing.call(thisArg, ...args)
					} catch (e) {
						logger(info)
						throw e // NOTE: THIS here is to represent DEPTH [as parsers can be VERY recursive indeed, it may be needed to eliminate the recursive errors on a case-by-case basis]; 
					}
				}
			}

		Although... This is rather general. Perhaps, better implement as a separate package; 

	3.23. Re-define the 'Parser' (StatefulStream): 

		Currently, a 'Parser' is a result of 'GeneralParser'; 
		This is NOT what one wants; 

		In particular, one needs a thing called STATEFUL STREAMS (StatefulStream); 

		Basically, this is a 'BasicStream' with the '.state' property; 
		This is very useful for complex parsing operations that DO NOT REQUIRE full-input parsing (one can delay execution); 

		ADD a 'Stateful' function, which does [basically]: 

			function Stateful (state: object) {
				return function (x: any) {
					x.state = state
				}
			}

		[Note: this can ALREADY be used in the form of 'Stateful' with 'StreamTokenizer' and 'TransformedStream']; 

		
	3.24. limitedStreamNavigate: FLAWED!
	
		Should handle the case where the '.pos' is A FUNCTION [but the 'position' ISN'T]; 
		THIS [fundamentally] needs the separation between the 'relative' and 'absolute' '.navigate'; 

			Once these are implemented, there'll be no problem whatsoever... 

			The (primary) issue with '.navigate'-ing using predicates is that it's NOT possible to navigate (generally) ABSOLUTELY using them; 
			Only the relative navigation is possible; 

			SEPARATING the navigation into 'absoluteNavigate' and 'relativeNavigate' (and defining the actual '.navigate' as the CONJUNCTION of the two), 
				will largely solve the issue. 
			
	3.25. MemoizableStreamClass: 

		This is a generalization of StreamClass; 
		The StreamClassInstance-s are ONLY capable of memoizing the very first value obtained via 'initCurr'; 

		This would (additionally) have two more methods: 

			1. memoize() - memoizes the value (any further .next() changes the value of the Stream, but '.curr' remains THE SAME); 
			2. unmemoize() - returns back to the flow of the Stream; 
	
4. Dependency management: 

	4.1. Create a 'proxy-op' library SPECIFICALLY for various optimizations based on Proxy-functions on different types/kinds of objects;	
		4.1.1. These (sometimes) can help GREATELY reduce memory-consumption; Example: the Slicer; Include those there...; 
