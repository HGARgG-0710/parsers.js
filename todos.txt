[GENERAL]
1. Check if this works with Deno; 	

[v0.3]

NOTE: nope, the version is NOT finished. 

	-2. JSDOC: 

		THIS Should be present ONLY for: 

			1. "Position/" utilities; 

A. testing: 
	A.1. Create list of modules to be tested; 
	A.2. Write out dependencies to be tested for each one of them; 
	A.3. Write the documentation (JSDoc), in order to be able to check the expected output/input of the given thing; 
	A.4. Write the tests (module-by-module); 
B. documentation (change/fix it...);
	B.1. Create new pages:
		B.1.1. Home: 
			B1.1.1. Motivation (write that the library was created/conceived primarily as a mean of refactoring of frequent parsing tasks/data-structures); 
			B1.1.2. "One good approach" principle (write that the library was made to have a single "intended" best approach for all the things that are possible to do using it); 
			B1.1.3. Examples [projects done using it]; 
			B1.1.4. Structure - explain how the library structure works (interfaces., methods., classes., utils.); 
			B1.1.5. Known issues (this lists known problems that the library currently has);
C. rewrite the CHANGELOG [too much has been altered since the "initial" v0.3]; 
	C.1. Walk through the last commit's state of v0.2.1, noting changes and writing them down [destructive]; 
	C.2. Walk through the v0.3 changes, and write them down [constructive];

Note: the new object-oriented approach will enable better speed and lesser structure-copying (better memory use); 
	PLUS: one can have the 'Streams' in question working AS TREES without the necessity for creation of the actual TreeStream-s
		(as the recursive Stream-s more or less serve the same function - only problem is populating them with the appropriate kinds of objects); 

[v0.4]

1. STACK! 
	The library is not too stack heavy, BUT it does have an (ultimate) stack-limitation
		when working with NestableStream-s and the 'nested' util (generally, anything that is NON-FLAT);
	This is very much impossible to solve on its own; 

	SOLUTION: use the CPS style. 
		Re-implement library (whilst keeping the non-CPS version) in CPS, 
		with an infinite 'stack'; 

	! THIS WILL REQUIRE FOR ONE TO FIRST IMPLEMENT THE INFINITE CPS-BASED STACK LIBRARY!
	That one should: 
		0. Be written in TypeScript; 
		Include Types: 
		1. InfiniteStack; 
		2. CPSArray (this is, ultimately, a CPS version of JS array);

	As, CPS is (quite) time-costly to actually run (due to amount of stack usage [primary] + the stack unwinding + additional checks...),
		this sort of thing would be useful for applications where speed of little importance
			(that is: NOT things like apps/websites/interpreters, and so forth; Stuff like AOT-compilers, perhaps);
	
2. Add various optimization data structures + utils + parser properties: 

	2.1. bufferize(process, size)(tree) - util

		Given a 'Tree', returns an array of values: 

			{
				childNumber: number,
				value: any
			}

		This (ultimately) does THE SAME thing
			as the 'TreeStream', BUT without losing the children's Tree-information. 
		Unlike the 'TreeStream', this is intended as
			a more persistent data structure with faster, 
			and NON-LINEAR (important) access than TreeStream.
		
		Would return a 'NodeBuffer' (which is just a kind of an array); 
		Indexing an array could be (potentially) noticeably faster than walking through a Tree 
			(particularly so with the 'TreeStream'); 

		The 'index' is the index FROM THE BEGINNING of the buffer to the current Node. 
		The 'childNumber' is the number of children that come AFTER the current node. 
			Children are read between positions from 'index' to 'index + childNumber', [where 'index' is the NODE'S POSITION! Keep it or keep it not...]; 
				with each 'child' being checked for its own children
					(which, if nonzero, are excluded from the current children, and are instead counted as grandchildren). 
		
		The 'value' is the actual value at the index (note: being 'process'ed - this is intended for removing/keeping children, primarily); 

		If size is used, it will ONLY use this many items from the tree (up to the maximum amount - the rest of positions will be assigned to 'undefined'); 

	2.2. Add a 'state.size' property to the parsers. 
		This (ultimately) counts the number of items inside the tree.
		Can be used with 'bufferize': 

			bufferize((x) => x, pstate.size)(pstate.result)	

	2.3. TreeStream: create two versions; 

		The 'TreeStream' (currently) is the 'LL' pre-order tree traversal algorithm Stream-implementation; 
		There should be ANOTHER - the 'LR' post-order tree traversal; 

		Rename the 'TreeStream' to 'TreeStreamPre', and create an implemnetation for the 'TreeStreamPost'; 
		This is (particularly) useful for some types of interpreters; 

		The Pre  visits the node, then its children one-by-one starting from the beginning. 
		The Post visits first the children, only THEN the parent.

	2.4. Implement a 'PartialValidator': 
		This, ultimatly, works in THE SAME WAY as the 'PatternValidator' and 'PatternTokenizer' (GENERALIZE THEM TO A SINGLE FUNCTION ALREADY!)
		Gets the recursive structure with all the 'split' and 'inserted' bits; 
		The 'PartialValidator' would RETURN THE INFORMATION FOR INFERENCE OF CORRECT/INCORRECT PARTS! 
		[Which it does by 'numbering' particular portions of a given Pattern]; 
		This would allow for a greater ability to analyze/point-out the errors in the original input;

		Unlike plain PatternValidator, it would return ALL the possibly available error information, not just the stuff about the index of the "failed" check, or coverage; 

	2.5. Implement a 'level-by-level TreeStream': 

		It would get an initial given 'level' (tree root), walk through all of its '.children', 
			then walk each of the '.children' themselves as levels (one after another...), THEN descending lower...; 

	2.6. Add a 'HashClass'-implementation of 'MapClass'; 

		Basically, takes the 'hash' function (rough sketch) and returns a hash-table based off it...: 

			function HashTable (hash) {
				return function (values, keys = new Set(), default = null) {
					return function (x) {
						return !keys.size || keys.has(x) ? values[hash(x)] : default
					}
				}
			}

		Great for generalizing optimizations of tables/hashes/maps...

		Implement special  cases of this ALSO (PARTICULAR hash-functions...): 

			1. LengthHash: 

				This is excellent for string-identifiers; 
				Given a set of strings (THAT CAN BE UPDATED!),
					one has a hash function: 

						(string) => string.length

				The thing in question is (supposed) to map a given string to an array/collection 
					of other strings of equal length, then map in this collection (which has a different interface...);

				NOTE: ANYTHING with a '.length' property is usable with this;
				
			2. TreeHash (a kind of 'Hash', based off 'Tree'-s): 
				Basically, given an 'Indexed<Type>' (WITH A '.length'), and given an 'array-tree', one does (rough sketch, indexation): 

					function ArrayTreeHash (tree) {
						return function (x) {
							let current = tree
							for (let i = 0; i < x.length; ++i) current = current[x[i]]
							return current
						}
					}

				NOTE: the actual 'TreeHash' would be more general and use 'x' as a MULTIINDEX!
					(tree) => tree.index(x)
					BUT: for this, it'd require a more 'generalized' version (in particular, USE LOOPS INSTEAD OF '.reduce')

				This can be used with strings/

	2.7. __ALWAYS__ USE 'for'-loops INSTEAD OF '.reduce'!
		This makes code MUCH more general. 
		In particular, one does so with the 'Tree'-s; 
		It'd allow to (for instance) store identifiers, and getting them via 'loops'; 

		Excluding some few special cases (like 'childIndex'), walk through the project, 
			AND REPLACE un-place-ly '.reduce'-s with proper loops...

	2.8. Add a module SPECIFICALLY for working with strings/identifiers/Sequence-s (currently: the 'Indexed' interface); 

		In particular, functions/abstractions: 

			1. UniqueSequenceTree;

				This is an 'IndexMap'+'Tree'-implementation working like: 

					1. '.index' of a given 'string' (or another '.length'-having structure) BASICALLY, finds the first "unique" level it's on; 

						So, for instance, having a set: 

							{ ann, ant, ben }

						Would yield an IdentifierTree: 

							0   1 2
							a,b-n-n,t

						This (basically) uses recursive objects + indexation
						(
							ant is found in 3 iterations; 
							an is found in 2 iterations; 
							'ben' is found in 1 iteration (only 'b' is stored);
						)

				Note: this implements a HashMap's 'hash'; 
				This is VERY good for frequent accesses to THE SAME value; 

			2. BinarySearchTree; 

				Same as 'UniqueSequenceTree', BUT it implements a Binary Search Tree.
				It works based on a provided comparison (a very rough indexation sketch): 

					function BinarySearchTree(tree, comparison) {
						return function (x) {
							let current = tree
							let greater
							while (current.length) current = current[+comparison(current, x)]
							return current.value
						}
					}
				
				NOTE: with (x, y) => x > y, can be used with identifiers; 

			3. shorten(names); 
				Given a sequence of "names" (strings/sequences),
					and a 'comparison' predicate for each of its elements,
						it would implement a name-shortening algorithm, 
							that would preserve the name uniqueness;
				
				The return value is an IndexMap; 

			4. renameable(names);
				Given an IndexMap of names (which could come from, for instance, 'shorten'), 
					the method: 

					1. Re-orders;
					2. Creates new name-map entries;

				In a fashion that would allow straightforward implementation of a sequential "exact replacement algorithm" based on the output: 

					1. Loop through a list of name-maps; 
						2. [In the loop] Rename current encounters of a name with its mapped value;	
					
				There are 2 operations that may be necessary: 

					1. creation of temp-names (when collisions in present names are far too high to re-order);
					2. re-order; 
				
				The algorithm for the 'renameable' function: 

					0. Keep the cached (met) names in a 'Set'; 
					1. Loop through the 'names' given: 
						1.0. If the name is in the cached Set, continue; 
						1.1. If the current 'value' of the 'name' is already present amongst 'keys' (another loop): 
							1.1.1. put the keys in question BEFORE the current value;
							1.1.2. '.swap' the two indexes;
							1.1.3. go one position back (because now one needs to check the "others" now); 
							1.1.4. cache the current amongst the checked names in a 'Set', (so that one doesn't get into an infinite loop);

	2.9. Replace the 'Tree' methods with in-place algorithms (not what this currently is...); 
		The 'copying' for Tree-s should be a WHOLE SEPARATE thing with ITS OWN module; 
		NOTE: the 'copying' in question occurs in methods 'MultValueTree' and 'RecursiveArrayTree'; 

		Namely: 

			1. RecursiveCopy:

				This is a method that deals with the 'ConstructibleTree's interface (basically, trees that can also be [generally] modified...);
				It creates a new such tree based off the current one; 

				Uses a general interface to copy arbitrary trees; 
				There has to be a 'flatCopy(): Tree' function for a given tree
					(which, repeated recursively, would yield a new tree, 
						and allow to preserve the reference to the underlying children WITHOUT
							preserving the reference to the tree itself...);

				This would be a 'FlatCopiableTree'; 
	
	2.10. Create a 'ModifiableStream' interface;

		It is (basically) a Stream, into which things can be INSERTED, whilst it is iterated. 
		Id est: 

			// ...
			input.next()
			input.insert(X) // calls another 'input.next()'; input.curr() now is 'X'; The thing RETURNS the result of the 'input.next()';

		Implement various different kinds of ModifiableStream-s; 

		1. A 'ModifiableTreeStream' "interface" (set of TreeStream-related implementations) would be a 'ConstructibleTree';

			There'd be different ModifiableTreeStream-s; 
			Their '.insert' would be based off how the tree was visited: 

				1. pre-order: it adds a NEW FIRST child to the current tree's node;
				2. post-order:
					1. IF current node has a parent already, adds a new parent to it
						(the current node; ID EST, adds a new CHILD to the current parent, and makes it the parent of the current node...)
					2. Otherwise, adds a node that is a FIRST CHILD of the current one; 
			
			There would also be some 'special' methods on 'TreeModifier', INDEPENDENT of the 'ModifiableTreeStream'-s [which would work with the TreeContext-s themselves]: 
			
				1. "insertSibling", which would insert a next sibling of the current element; 
				2. "insertLast", which would insert a child TO THE END of the tree's '.children';
				3. "insertChild", which would insert a child at a given index; 
				4. 'prependSibling', which would add a sibling BEFORE the current child; 

				PROBLEM: this sort of thing would OCCASIONALLY INVALIDATE the 'last' index; 
					It would have to be re-computed in such cases; 

			NOTE: there'd be a special new "class" of objects called 'TreeModifier' (analogous to 'TreeWalker'); 
				NOTE: Due to how the 'multi-index' of a 'Tree' would be "contained" within the 'TreeWalker',
					yet it would STILL need to be accessed by the 'TreeModifier' [in Stream Contexts...], 
						one might NEED to unite the two...; 

					IDEA: TreeIndexContext;
						This, basically, contains a triple: 

							{
								index: MultiIndex
								walker: TreeWalker
								modifier: TreeModifier
							}

						And the TreeWalker, TreeModifier, would be 'bound' to the current one (that is, they'd be taking an argument of 'multindex');

			The 'TreeModifier' implementations would HAVE to have a sort of "Modifiable" Tree (which is a special case of a 'Tree'); 
			A 'ChildrenTree' (Tree with '.children') is a GREAT fit for it...; 

		2. A 'ModifiablePositionalStream' would be a wrapper around another 'PositionalStream', 
			which would have a map of 'Positions', into which things were 'inserted', and would return new stuff accordingly...
			It is ALSO a 'PositionalStream'; 

			NOTE: for this stuff to WORK generally, one needs to define an 'AdditivePosition',
				one for which the 'skip(stream: PositionalStream, plus: Position)', or 'add(stream: PositionalStream, plus: Position)', 
					would exist. 

					'Number' special case of 'add(...)': 
						(a, b) => a + b
					
					Basically, just "goes forward"; 
					Similarly, there'd be a 'backout(stream: PositionalStream, plus: Position)' [or call it 'return'] method for these; 

					For numbers, definition is: 
						(a, b) => a - b

			The ModifiablePositionalStream would be a PositionalStream ALSO, which would permit one to 
				"stack them up" on top of one another (which is good for semantics separation...). 

		3. A 'ModifiableSplicableStream' would be a 'ModifiableStream' for 'Splicable'-s: 

			A 'Splicable' is an interface (extension of 'Indexed') with an Array-like .splice(index: number, toDelete: number, ...items: any) interface;
			Arrays are splice-ables; 

			The implementation would (basically) do: 

				{
					...InputStream(splicable),
					insert: function (X) {
						this.input.splice(this.pos, 0, X)
					}
				}

	2.11. CREATE A LOT OF Proxy-based OPTIMIZATION STRUCTURES!
		These are MIGHTY! [allow to save memory, and so forth...]; 
		IDEA: maybe, even create a library for these...; 
		
	2.12. Expand on the 'Position' type further;

		Allow for creation of more "exotic" types;
		Example: 

			"go up to nearest point in the past defined by predicate 'P', then another 5 positions", 

		should be something like: 

			[P, 5] // with 'P.direction = false'; 
		
		Allow "nesting" positions like so, create a proper PositionEvaluator (current thing is VERY limited); 

		The 'RelativePositionEvaluatorStream' would (ultimately) create a 'Stream' of values, defined by this "sequence"
			of Position-s (call it 'PositionSequence = Position[]'), and which would be entirely relative to one another; 
			Example: given [3, 6] it would get the 3'rd, then the (3 + 6) = 9'th positions of the Stream; 

		The 'AbsolutePositionEvaluatorStream' would (similarly) interpret a sequence of 'Position's,
			but relative to the initial Stream (not one another).
			Example: given [3, 6] it would get positions 3 and 6 relative to the initial Stream; 
		
		Then, GENERALIZE THIS to a 'PortionPosition' [which is the pair '[Position, Position]' used in 'LimitedStream'],
			to also use this with 'LimitedStream';

		So, 'PositionSequence = (Position | [Position, Position])[]' will define a new Stream based of a given one
			via the 'AbsolutePositionEvaluatorStream' and 'RelativePositionEvaluatorStream'; 

	2.13. RELAX overly demanding interface and types definitions/requirements;
		Example: inputStreamCopy, inputStreamNavigate; 

			These do not NEED to have all the parts of the 'InputStream' definition (even though they are originally implemented to work with it);
			RE-DEFINE them...;

	2.14. [Idea?] Create an error-handling API for the 'v0.4';
		Create means of: 

			1. Stacking different levels of exceptions (the 'try-catch' blocks); 
			2. Assigning relevant debug information to them;

		This is (primarily) for the development process of the parsers; 
		
		Define a Catcher [rough sketch]: 

			function Catcher (info: DebugInfo, logger: Function) {
				return function (thing: Function, thisArg: any, args: any) {
					try {
						thing.call(thisArg, ...args)
					} catch (e) {
						logger(info)
						throw e // NOTE: THIS here is to represent DEPTH [as parsers can be VERY recursive indeed, it may be needed to eliminate the recursive errors on a case-by-case basis]; 
					}
				}
			}

		Although... This is rather general. Perhaps, better implement as a separate package; 
		
	2.15. limitedStreamNavigate: FLAWED!
	
		Should handle the case where the '.pos' is A FUNCTION [but the 'position' ISN'T]; 
		THIS [fundamentally] needs the separation between the 'relative' and 'absolute' '.navigate'; 

			Once these are implemented, there'll be no problem whatsoever... 

			The (primary) issue with '.navigate'-ing using predicates is that it's NOT possible to navigate (generally) ABSOLUTELY using them; 
			Only the relative navigation is possible; 

			SEPARATING the navigation into 'absoluteNavigate' and 'relativeNavigate' (and defining the actual '.navigate' as the CONJUNCTION of the two), 
				will largely solve the issue. 
			
	2.16. MemoizableStreamClass: 

		This is a generalization of StreamClass; 
		The StreamClassInstance-s are ONLY capable of memoizing the very first value obtained via 'initCurr'; 

		This would (additionally) have two more methods: 

			1. memoize() - memoizes the value (any further .next() changes the value of the Stream, but '.curr' remains THE SAME); 
			2. unmemoize() - returns back to the flow of the Stream; 

	2.17. Minor refactoring (StreamClass): 

		Create a special case for the 'StreamClass' - the 'WrapperStreamClass'; 
			Basically, this works in a fashion similar to the 'InputStream', 'TransformedStream', and 'NestedStream', and others such (generally, UnderStream-s and Inputted): 

				1. There is 'iter' function (for iteration); 
				2. There is 'curr' function (for 'initGetter' and the definition of 'baseNextIter'); 
				3. Then, the 'baseNextIter' is defined as: 

					{
						iter.call(this)
						return curr()
					}

	2.18. Try re-doing the project's type-system? [again...]

		The direct use TypeScript's 'interface's cause huge issues surrounding the 'conditional' properties
			(in particular, the need to duplicate to make everything work). 

		See, if not (mayhaps), it is feasible to re-write everything via 'extends BasicStream'-sort of thing
			(meaning, the needed StreamType-s would be "inserted" where desired...); 

	2.19. BreakableStream - a stream-class that produces instances, which : 

		1. Are capable of being "broken" via different positions; 
			1.1. can eliminate parts of the given stream, IF it's a 'number' or a StaticPosition,
			1.2. Gets a chunk of the given 'Stream' if it's: 
				1.2.1. DualPosition [a LimitedStream: NOTE: this literally builds a sub-LimitedStream]; 
				1.2.2. PositionPredicate [a property to be followed by the next chunk]; 
		2. Have a sub-stream of '.input', on which they operate; 
		3. Take in a sequence of (Position | DualPosition)[]
		
		NOTE: this is, basically, same stuff as the 'AbsolutePositionEvaluatorStream', BUT, 
			it's "not-picky" in the sense that the FIRST of the allowed occurences will be used, 
			AND, it will be used without preference; 

			Also - this works UNTIL THE END OF THE GIVEN Stream, NOT until the end of THE EVALUATED ARRAY; 

		SO, what is given is an Array, each of possibilities in which are "checked" for getting picked for 
			the Stream, then the first one getting its "go" as the '.curr'; 

		BUT, the given 'Array' will actually be several, which are ORDERED BY ATTEMPT in the following fashion: 

			1. limits[] - the array of 'DualPosition's; These define 'LimitedStream'-s [NOTE: these can contain pairs of predicates also!]; 
				1.1. In particular, this defines the predicate-limiting on the given Stream (in the sense, that, the piece matched by the first)
			2. nest[] - the array of dual 'StreamPredicate'-s used to define the nesting; 
			3. preserve[] - a set of 'Position'-s for IMMIDIATE matches; 
				3.1. These are added to the Stream ONE-BY-ONE and ONLY if none of the above [.predicates, .limits] match; 
			4. skip[] - a Position-s array; Will be used FOR SKIPPING items sequentially; 
				5.0. THIS is only matched if NOTHING from 'preserve' is matched; 
				5.1. StaticPosition: This will take the next one that is 'x: StaticPosition' '.next'/'.prev' (depending on direction) calls away
				5.2. PredicatePosition: This will skip the items FOR AS LONG as the given predicate holds...;
			5. halt[] - this is a set of Positions, that, if met/reached will TERMINATE the given Stream's consumption; 
			6. default - this is a 'special' action, if NOTHING amongst these matches, it'll do one of 'preserve', 'halt' or 'skip' [or other...]; 

		Whether the 'predicates', 'limits', 'preserve', or 'skip' are checked for first, the user can choose; 

		IDEA: 
			No, don't do that; 
			INSTEAD: categorize; That is, a list of things is given (BreakPattern): 

				1. BreakPattern = ((Position | DualPosition) | BreakPattern)[] // tree-like structure
				2. Each of the elements of 'BreakPattern' is one of 'type: "..."' (one of the above)
				3. WHEN ARRAY IS PASSED, the given thing is being 'sub-broken'; Thus, one can work through trees; 

				ABOUT ITERATION: 

					Once having achieved the '.break'-ing of a BreakableStream, one does the following: 
						
						1. keep the 'currType' property on the 'BreakableStream', which IS 
							one of the allowed types for a given thing; 
						2. Based off them, RESPOND; 
							2.1. The response can (for instance) be based off a 'TransformedStream', or 'NestedlyTransformed' stream; 
		
		ALL the 'BreakableStream'-s are RELATIVE [in the sense that the current position is used to grab the future '.curr'-s]; 
		
		These can serve as a wonderful alternative to PatternTokeniz-ing via Regular Expressions; 
		Moreover, 'BreakableStream'-s are (very much) capable of replacing sequences of operations inside of 'IndexMap'-s for StreamTokenizer-s; 
			In that, it's entirely feasible to define any operation currently present within the parser.js library using them; 

			Example: parse string: "..."

				(string) => BreakableStream(string, {})

	2.20. [later?] AlphanumericEnum; [Note: this is GENERAL - uses a linearly ordered set of symbols]

	2.21. CREATE a new file 'constants': this will keep track of in-library constants; 
		Put the 'PRE_CURR_INIT', and other such things THERE; 

	2.22. [Unhandled Edge case] The 'default .curr' in events that the '.isCurrEnd' is AUTOMATICALLY false ON-DEFINITION for the given Stream IS NOT defined; 

		There should be a '.defaultCurr' property, for defining the value of the '.curr' whenever the Stream is initialized empty; 
		This is particularly useful for ModifiableStream-s, as for even non-empty ones, this can, indeed, be an actual case; 

		Although, for the 'static' (inplace/read-only) Streams, this sort of thing is ONLY possible, if the "reading rule" of: 

			while (!stream.isEnd()) {
				// ... do stuff with 'stream'
			}
		
		Is disobeyed; 

		Similarly, one SHOULD allow the user to define the value for '.curr' REGARDLESS, of whether the Stream is empty or not
			(that being, '.defaultCurr' would work for Stream-s that ended EVEN IF they aren't empty); 
	
	2.23. MINOR ISSUE: the 'PredicateStream' - that one DOESN'T have a very well defined 'defaultIsEnd' predicate; 
		In other words, IT REQUIRES for the given thing to be able to tell WHETHER OR NOT in the given Stream, there is
			an item with given predicate; 

		Which is something of a problem, as it requires iterating over the Stream (and is, thus, useless); 
		
		Practical solution for this: 

			{
				// ...
				const hasValue = has(pred)(stream) // changes the 'Stream' position
				if (hasValue) {	
					const S = PredicateStream(stream, pred) // the '.curr' guaranteedly becomes the '.curr' in the 'S'
					// ...
				} else {
					// ... handle the alterior case...
				}
			}

		Think whether an elegant solution may be found (or whether this is to be simply left to the docs...); 

	2.24. Optimize minitua (that is, just go through the code, removing unnecessary repetitions of things, useless work and so forth...); 
		When the same (even tiny) operations get repeated a large number of times, the speed decay accumulates; 
		Try to make the library code that avoids this stuff fundamentally; 
		
	2.25. More "conditional" properties (like the conditional '.finish', '.rewind', and so forth...); 

		note: these MUST depend on assumptions regarding '.finish'-ness (and so forth) of underlying stream/-s, WHEN they are present. 
			This is because otherwise, the whole "optimization thing" isn't existent
				(example ProlongedStream's '.finish' MUST have all its underlying Stream-s being checked); 
			
		Properties: 

			1. finish (complete);
			2. rewind (likewise, complete); 
			3. copy - let EVERY stream available be copiable; 
			4. navigate - where appropriate; 

	2.26. utility - findNestedEnd: 

		Given a 'ReversibleStream'/'NavigableStream', it does: 

			1. Walk through the Stream (similarly to 'nest' - counting 'depth');
			2. Finds the location, at which the end of the nested block lies (note: A NUMBER); 
			3. Returns that location, whilst also altering the location of the 'Stream' given; 

		This, basically, allows one to "know" where to end the parsing of a given thing (WHEN it's needed to be parsed LATER)!

	2.27. BufferizedStream - a wrapper around a given Stream, to enable the storage of a buffer
		for its operations; 

		Once '.next' is called, it stores the '.curr' inside the inner 'buffer', ONLY IF the user-given '.predicate'
			HOLDS!
	
	2.28. Use prototypal inheritance to save memory; 

		Restructure code a little - provide A SINGLE prototype, that is to be used by the 'constructor' (which are, in practice,
			really just 'Object.create(INITIAL)' + setting of additional properties that are passed)
		
		The user can do this sort of thing themselves, but for operations that are heavy on 'Object.create' usage, it may be useful
			to provide an alias; 

		Thus, there'd be BOTH exports for things that are StreamClass-es (functions for producing base prototypes), and the prototype 
			objects themselves; 

		Same goes for objects that are used within the definitons of different 'Parsers"; 
	
3. Dependency management: 
	3.1. Create a 'proxy-op' library SPECIFICALLY for various optimizations based on Proxy-functions on different types/kinds of objects;	
		3.1.1. These (sometimes) can help GREATELY reduce memory-consumption; Example: the Slicer; Include those there...; 
